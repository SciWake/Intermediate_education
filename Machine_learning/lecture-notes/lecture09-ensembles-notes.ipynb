{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f59e6f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Бэггинг, случайные леса и разложение ошибки на смещение и разброс</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. Бутстрап</h1>\n",
    "\n",
    "Рассмотрим простой пример построения композиции алгоритмов. Пусть дана конечная выборка $X = (x_i, y_i)_{i=1}^{\\ell}$ с вещественными ответами. Будем решать задачу линейной регрессии. Сгенерируем подвыборку с помощью *бутстрапа*. Равномерно возьмем из выборки $\\ell$ объектов с возвращением. Отметим, что из-за возвращения среди них окажутся повторы. Обозначим новую выборку через $X_1$. Повторив процедуру $N$ раз, сгенерируем $N$ подвыборок $X_1, \\dots, X_N$. Обучим по каждой из них линейную модель регрессии, получив *базовые алгоритмы* $b_1(x), \\dots, b_N(x)$.\n",
    "\n",
    "Предположим, что существует истинная функция ответа для всех объектов $y(x)$, а также задано распределение на объектах $p(x)$. В этом случае мы можем записать ошибку каждой функции регрессии\n",
    "\n",
    "$\\large \\varepsilon_j(x) = b_j(x) - y(x),\n",
    "\\qquad\n",
    "j = 1, \\dots, N,$\n",
    "\n",
    "и записать матожидание среднеквадратичной ошибки и это будет характеристикой качества $b_{j}(x)$ модели на всем пространстве объектов\n",
    "\n",
    "$\\large \\mathbb{E}_x (b_j(x) - y(x))^2\n",
    "=\n",
    "\\mathbb{E}_x \\varepsilon_j^2(x).$\n",
    "\n",
    "Средняя ошибка построенных функций регрессии имеет вид\n",
    "\n",
    "$\\large E_1\n",
    "=\n",
    "\\frac{1}{N}\n",
    "\\sum\\limits_{j = 1}^{N}\n",
    "\\mathbb{E}_x \\varepsilon_j^2(x).$\n",
    "\n",
    "Предположим, что ошибки несмещены (первое предположение) и некоррелированы (второе предположение), которое означет, что если $i$ модель ошиблась на некотором объекте, тогда из этого нельзя сделать предположения о $j$ модели на данном объекте, ошибается она или нет:\n",
    "\n",
    "$\\large \\begin{align*}\n",
    "    &\\mathbb{E}_x \\varepsilon_j(x) = 0;\\\\\n",
    "    &\\mathbb{E}_x \\varepsilon_i(x) \\varepsilon_j(x) = 0,\n",
    "    \\quad\n",
    "    i \\neq j.\n",
    "\\end{align*}$\n",
    "\n",
    "Построим теперь новую функцию регрессии,\n",
    "которая будет усреднять ответы построенных нами функций:\n",
    "\n",
    "$\\large a(x) = \\frac{1}{N} \\sum\\limits_{j = 1}^{N} b_j(x).$\n",
    "\n",
    "Найдем ее среднеквадратичную ошибку:\n",
    "\n",
    "$\\large \\begin{align*}\n",
    "    E_N\n",
    "    &=\n",
    "    \\mathbb{E}_x \\Biggl(\n",
    "        \\frac{1}{N} \\sum\\limits_{j = 1}^{n} b_j(x)\n",
    "        -\n",
    "        y(x)\n",
    "    \\Biggr)^2\n",
    "    =\\\\\n",
    "    &=\n",
    "    \\mathbb{E}_x \\Biggl(\n",
    "        \\frac{1}{N} \\sum\\limits_{j = 1}^{N} \\varepsilon_j(x)\n",
    "    \\Biggr)^2\n",
    "    =\\\\\n",
    "    &=\n",
    "    \\frac{1}{N^2}\n",
    "    \\mathbb{E}_x \\Biggl(\n",
    "        \\sum\\limits_{j = 1}^{N} \\varepsilon_j^2(x)\n",
    "        +\n",
    "        \\underbrace{\\sum\\limits_{i \\neq j} \\varepsilon_i(x) \\varepsilon_j(x)}_{=0}\n",
    "    \\Biggr)\n",
    "    =\\\\\n",
    "    &=\n",
    "    \\frac{1}{N} E_1.\n",
    "\\end{align*}$\n",
    "\n",
    "Мы получили, что математическое ожидание ошибки композииции в $N$ раз меньше чем математическое ожидание ошибки одной модели. Таким образом, усреднение ответов позволило уменьшить средний квадрат ошибки в $N$ раз!\n",
    "\n",
    "Следует отметить, что рассмотренный нами пример не очень применим на практике, поскольку мы сделали предположение о некоррелированности ошибок, что редко выполняется. Если это предположение неверно, то уменьшение ошибки оказывается не таким значительным. Позже мы рассмотрим более сложные методы объединения алгоритмов в композицию, которые позволяют добиться высокого качества в реальных задачах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab93826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
