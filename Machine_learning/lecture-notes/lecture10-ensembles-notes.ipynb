{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6786cf4a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Градиентный бустинг</h1>\n",
    "\n",
    "Ранее мы изучили бэггинг и случайные леса — подходы к построению композиций, которые независимо обучают каждый базовый алгоритм по некоторому подмножеству обучающих данных. При этом возникает ощущение, что мы используем возможности объединения алгоритмов не в полную силу, и можно было бы строить их так, чтобы каждая следующая модель исправляла ошибки предыдущих. Ниже мы рассмотрим метод, который реализует эту идею — градиентный бустинг, предложенный Фридманом [1]. Он работает для любых дифференцируемых функций потерь и является одним из наиболее мощных и универсальных на сегодняшний день.\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. Бустинг в задаче регрессии</h1>\n",
    "\n",
    "Рассмотрим задачу минимизации квадратичного функционала:\n",
    "\n",
    "$\\large \\frac{1}{\\ell}\n",
    "\\sum\\limits_{i = 1}^{\\ell}\n",
    "    (a(x_i) - y_i)^2\n",
    "\\to\n",
    "\\underset{a}{\\text{min}}$\n",
    "\n",
    "Будем искать итоговый алгоритм в виде суммы *базовых моделей* (weak learners) $b_n(x)$:\n",
    "\n",
    "$\\large a_N(x)\n",
    "=\n",
    "\\sum\\limits_{n = 1}^{N}\n",
    "    b_n(x)$\n",
    "\n",
    "где базовые алгоритмы $b_n$ принадлежат некоторому семейству $\\mathbb{A}$. Построим первый базовый алгоритм по всем базовым моделям $b \\in \\mathbb{A}$:\n",
    "\n",
    "$\\large a_1(x) = b_1(x)\n",
    ":=\n",
    "\\underset{b \\in \\mathbb{A}}{\\text{argmin}}\n",
    "    \\frac{1}{\\ell}\n",
    "    \\sum\\limits_{i = 1}^{\\ell}\n",
    "        (b(x_i) - y_i)^2$\n",
    "        \n",
    "Посчитаем насколько базовая модель ошибается на каждом объете:\n",
    "\n",
    "$\\large s_i^{(1)} = y_i - a_1(x_i)$ - сдвиги\n",
    "\n",
    "\n",
    "Если прибавить эти остатки к ответам построенного алгоритма, то он не будет допускать ошибок на обучающей выборке. Значит, будет разумно построить второй алгоритм так, чтобы его ответы были как можно ближе к остаткам:\n",
    "\n",
    "$\\large b_2(x)\n",
    ":=\n",
    "\\underset{b \\in \\mathbb{A}}{\\text{argmin}}\n",
    "    \\frac{1}{\\ell}\n",
    "    \\sum\\limits_{i = 1}^{\\ell}\n",
    "        (b(x_i) - s_i^{(1)})^2$\n",
    "        \n",
    "Если $b_2$ идеальна, тогда мы берем копозицию из двух моделей и она будет всюду выдавать правиьный овет $y_i$:\n",
    "\n",
    "$\\large a_2(x_i) = b_1(x_i) + s_i^{(1)} = b_1(x_i) + y_i - a_1(x_i) = y_i$\n",
    "\n",
    "Так как зачастую этого недостаточно, тогда мы посчитаем следующие сдвиги:\n",
    "\n",
    "$\\large s_i^{(2)} = y_i - a_2(x_i)$ - сдвиги\n",
    "\n",
    "Каждый следующий алгоритм тоже будем настраивать на остатки предыдущих:\n",
    "\n",
    "\n",
    "$\\large s_i^{(N)} = \n",
    "y_i - \\sum\\limits_{n = 1}^{N - 1} b_n(x_i)\n",
    "=\n",
    "y_i\n",
    "-\n",
    "a_{N - 1}(x_i)\n",
    "\\qquad\n",
    "i = 1, \\dots, \\ell$\n",
    "\n",
    "$\\large b_N(x)\n",
    ":=\n",
    "\\underset{b \\in \\mathbb{A}}{\\text{argmin}}\n",
    "    \\frac{1}{\\ell}\n",
    "    \\sum\\limits_{i = 1}^{\\ell}\n",
    "        (b(x_i) - s_i^{(N)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de92227",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2. Градиентный бустинг</h1>\n",
    "\n",
    "Пусть дана некоторая дифференцируемая функция потерь $L(y, z)$. Будем считать, что мы обучили первую модель $b_1(x)$. Как построить следующие модели? Обучение $b_N$ запишем следующую задачу:\n",
    "\n",
    "$\\large \\sum\\limits_{i = 1}^{\\ell} L(y_i, a_{N-1}(x_i) + b_N(x_i)) \\to \\underset{b_N(x)}{\\text{min}}$\n",
    "\n",
    "Где $a_{N-1}(x_i) = \\sum\\limits_{n=1}^{N-1} b_n(x)$ композиция из построенной $N-1$ модели.\n",
    "\n",
    "В этой задаче, мы хотим найти $b_N$ модель такой, что если ее прибавить к построенной композиции, тогда должна получиться более маленькая ошибка. \n",
    "\n",
    "Если фукнция потерь удовлетворяет тому, что можно перенести агрумент из одной части в другую $L(y, a+b) = L(y-a, b)$, тогда мы можем дообучать базовую модель на новую целевую переменную:\n",
    "\n",
    "$\\large \\sum\\limits_{i = 1}^{\\ell} L(y_i - a_{N-1}(x_i), b_N(x_i)) \\to \\underset{b_N(x)}{\\text{min}}$, тогда мы получаем задачу обучения базовой модели с обновленной целевой переменной, которая равна разности. \n",
    "\n",
    "Но, не все функции потерь способны удовлетворять этому требованию. Поэтому, нам необходим другой подход."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd83c1f",
   "metadata": {},
   "source": [
    "### Другой подход\n",
    "\n",
    "Ответим в первую очередь на следующий вопрос: если бы в качестве алгоритма $b_N(x)$ мы могли выбрать совершенно любую функцию, то какие значения ей следовало бы принимать на объектах обучающей выборки? Иными словами, нам нужно понять, какие числа $s_1, \\ldots, s_{\\ell}$ надо выбрать для решения следующей задачи:\n",
    "\n",
    "$\\large \\sum\\limits_{i = 1}^{\\ell}\n",
    "    L(y_i, a_{N - 1}(x_i) + s_i)\n",
    "\\to\n",
    "\\underset{s_1, \\dots, s_\\ell}{\\text{min}}$\n",
    "\n",
    "\n",
    "Понятно, что можно требовать $s_i = y_i - a_{N - 1}(x_i)$, но такой подход никак не учитывает особенностей функции потерь $L(y, z)$ и требует лишь точного совпадения предсказаний и истинных ответов. Наприме, имеется не симметричная фукнция потерь, которая по разному штрафует за отклонения, за перепрогноз штраф растет быстрее. Тогда при равной аболютной ошибке штрафы для объектов должны быть разными, следовательно $s_i$ должно на объектах с большим штрафом хотеть больше уменьшить ошибку, так как это внесет большой вклад в ошибку фукнции потреь. Следовательно, мы хотим получить более крупные корректировки для объектво, которые в правой ветке функции потерь, но если использовать текущий вариант, тогда корректировка будет одинаковой для двух объектов, что плохо.\n",
    "\n",
    "Более разумно потребовать, чтобы сдвиг $s_i$ был противоположен производной функции потерь в точке: $z = a_{N - 1}(x_i)$:\n",
    "\n",
    "$\\large s_i\n",
    "=\n",
    "-\n",
    "\\left.\n",
    "\\frac{\\partial L}{\\partial z}\n",
    "\\right|_{z = a_{N - 1}(x_i)}$\n",
    "\n",
    "Мы придумали чему должны равняться корректировки, но это на данный момент просто числа, а нам необходимо обучать модели. Так как мы знаем, чему дожна быть равна корректировка в $L$ точках, тогда, обучим базовую модель так, чтобы она была как можно ближе к $s_i$. Если базовая модель будет равняться примено сдвигу, тогда мы сдвиним ошибку в меньшую сторону, так как $b_N$ будет двигать в ту сторону, в которую ошибка будешь уменьшаться. Следовательно, будем обучать очередную базовую модель на следующую задачу:\n",
    "\n",
    "$\\large \\frac{1}{\\ell}\\sum\\limits_{i = 1}^{\\ell} (b_N(x_i) - s_i)^2 \\to \\underset{b_N(x)}{\\text{min}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfff1d",
   "metadata": {},
   "source": [
    "### Причина обучения на MSE\n",
    "\n",
    "Почему не обучаем дерево на исходную фукнцию потерь?\n",
    "\n",
    "$\\large \\frac{1}{\\ell}\\sum\\limits_{i = 1}^{\\ell} L(s_i, b_N(x_i)) \\to \\underset{b_N(x)}{\\text{min}}$\n",
    "\n",
    "Обучение на MSE может бы . Расскроем квадрат функционала ошибки:\n",
    "\n",
    "$\\large \\frac{1}{\\ell}\\sum\\limits_{i = 1}^{\\ell} (b_N^2(x_i) - 2 b_N^2(x_i) s_i + s_i^2) \\to \\underset{b_N(x)}{\\text{min}}$\n",
    "\n",
    "Тогда $s_i^2$ - это конастанта, поэтому можно его выкинуть. $b_N^2(x_i)$ в некоторой степени регуляризатор. И остается $-2 b_N^2(x_i) s_i$, которое мы минимизируем, если убрать минус тогда это необходимо максимизировать. Это выражение является скалярным произведение выходов модели с остатками, то есть, это угол между направлением в котором необходимо сдвигать прогнозы композиции и направлением, которое дерево смогло выучить, и мы хотим чтобы эти направления были как можно сильнее соноправленными.\n",
    "\n",
    "Получаем, что в бустинге две фукнции потерь, исходная, которая используется для рассчета градинета и ещё одна для обучения базовой модели на градиент."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c0987e",
   "metadata": {},
   "source": [
    "### Почему это называется градиентным бустингом?\n",
    "\n",
    "Предположим, что в выборке всего два объекта \n",
    "\n",
    "* $\\ell = 2$\n",
    "\n",
    "* $X = \\{(x_1, y_1), (x_2, y_2)\\}$\n",
    "\n",
    "Будем на этой выборке обучать бустинг, тогда по оси $x$ будет прогноз на первом объекте $a_N(x_1)$, на оси $y$ будет нарисован прогноз текущей композиции на втором объекте $a_N(x_2)$. И нарисуем линии уровня ошибки этой модели, например, $L(y_1, a_N(x_1)) + L(y_2, a_N(x_2))$.\n",
    "\n",
    "* Выбираем первую константную модель и ставим точку на графике. \n",
    "\n",
    "* Считаем сдвии, то есть, считаем градиент нашего фукнционала $L(y_1, a_N(x_1)) + L(y_2, a_N(x_2))$, по  параметрам $a_N(x_1), a_N(x_2)$. Следовательно, мы считаем куда необходимо менять прогнозы на объектах, чтобы ошибка уменьшилась как можно сильнее. После рассчетов, перемещаемся на графике в сторону сдвига.\n",
    "\n",
    "* Подбираем модель $b_2$ такой, чтобы она аппроксимировала полученное направление. Дальше мы строим модель и прибавляем к композиции, так как она довльно простая, то сдвинимся немного в другую сторону, переместившись в следующую точку.\n",
    "\n",
    "* После в этой точке считаем градиент, аппроксимиров его следующей моделью\n",
    "\n",
    "* ...\n",
    "\n",
    "Получается, что на каждом шаге мы считаем куда необходимо сдвинуть прогноз композии, аппроксимируем это направление и двигаемся в его направлении. И итоговая композиция моделей $a_N$ приходит в точку оптимума.\n",
    "\n",
    "Следовательно, градиентный бустинг - это градиентый спуск в пространстве прогнозов композиции на обучающей выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea1e96",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">3. Регуляризация</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fb48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
