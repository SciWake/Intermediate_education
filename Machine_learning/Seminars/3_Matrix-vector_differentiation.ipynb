{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Матрично-векторное дифференцирование</h1>\n",
    "\n",
    "Как правило, дифференцируемые модели обучаются с помощью градиентного спуска,\n",
    "а для него важно уметь считать градиент функционала ошибки по параметрам модели.\n",
    "Можно считать градиент покоординатно, а потом пристально смотреть на формулы и\n",
    "пытаться понять, как это может выглядеть в векторной форме.\n",
    "\n",
    "Гораздо проще считать градиент напрямую - а для этого поможет знание градиентов\n",
    "для основных функций и основных правил матрично-векторого дифференцирования.\n",
    "\n",
    "<h1 style=\"color:#008B8B\">Основные понятия</h1>\n",
    "\n",
    "Всюду в дальнейшем будут использоваться следующие стандартные обозначения:\n",
    "1. $\\mathbb{R}$ обозначает множество вещественных чисел;\n",
    "\n",
    "2. $\\mathbb{R}^n$ обозначает множество всех n-мерных вещественных вектор-столбцов;\n",
    "\n",
    "3. $\\mathbb{R}^{m \\times n}$ обозначает множество всех вещественных матриц с $m$ строками и $n$ столбцами;\n",
    "\n",
    "4. $\\mathbb{S}^n$ обозначает множество всех $n \\times n$ вещественных симметричных матриц.\n",
    "\n",
    "5. $\\mathbb{S}_{+}^n$ и $\\mathbb{S}_{++}^n$ обозначают множество всех $n \\times n$ вещественных симметричных положительно полуопределенных и положительно определенных матриц соответственно;\n",
    "\n",
    "6. $I_n$ обозначает единичную матрицу размера $n$.\n",
    "\n",
    "Заметим, что под векторами из $\\mathbb{R}^n$ всюду будут подразумеваться именно вектор-столбцы (а не, например, вектор-строки); таким образом, $\\mathbb{R}^n = \\mathbb{R}^{n \\times 1}$, но $\\mathbb{R}^n \\ne \\mathbb{R}^{1 \\times n}$. Напомним, что $\\mathbb{R}, \\mathbb{R}^n, \\mathbb{R}^{m \\times n}$ и $\\mathbb{S}^n$ являются вещественными векторными пространствами (со стандартными операциями сложения и\n",
    "умножения на число). \n",
    "\n",
    "Для матрицы $A \\in \\mathbb{R}^{n \\times n}$ символ $Tr(A) := \\sum\\limits_{i=1}^n a_{ii}$ обозначает ее след."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Производная</h2>\n",
    "\n",
    "**Определение производной для одной переменной**\n",
    "\n",
    "Представим геометрический смысл производной, рисунок в голове.\n",
    "$\\large f(x_0)' = \\lim\\limits_{\\Delta x \\to 0} \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} = \\lim\\limits_{\\Delta x \\to 0} \\frac{\\Delta y}{\\Delta x}$\n",
    "\n",
    "$\\large \\frac{\\Delta y}{\\Delta x} = tg{\\alpha}$ из $tg$ угла секущей следут, что угол наклона секущей стремится к углу наклона касательной:\n",
    "\n",
    "$\\large f(x_0)' = \\lim\\limits_{\\Delta x \\to 0} \\frac{\\Delta y}{\\Delta x} = tg \\varphi$\n",
    "\n",
    "**Дифференциал функции**\n",
    "\n",
    "$\\large tg \\varphi = \\frac{\\mathrm{d}y}{\\Delta x}$ и учитывая, что $tg \\varphi = f'(x_0)$ получаем:\n",
    "\n",
    "$\\large \\mathrm{d}y = tg \\varphi \\cdot \\Delta x$\n",
    "\n",
    "$\\large \\mathrm{d}[f(x_0)]= f'(x_0) \\cdot \\Delta x$ Предельно малое значение $\\Delta x$ часто обозначают через $\\mathrm{d}x$, поэтому формула принимает вид:\n",
    "\n",
    "$\\large \\mathrm{d}[f(x_0)] = f'(x_0) \\cdot \\mathrm{d}x$ Скинем  в знаменатель противоположной части:\n",
    "\n",
    "$\\large f'(x_0) = \\frac{\\mathrm{d}[f(x_0)]}{\\mathrm{d}x}$ До сих пор речь шла о производной и дифференциале в единственной «подопытной» точке $x_0$. Но ведь в качестве   можно взять ЛЮБУЮ ТОЧКУ $x$ рассматриваемого интервала!\n",
    "\n",
    "$\\large f'(x) = \\frac{\\mathrm{d}[f(x)]}{\\mathrm{d}x} \\Rightarrow y' = \\frac{\\mathrm{d}y}{\\mathrm{d}x}$  А это не что иное, как обозначение производной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">1. Вывод основных формул</h1>\n",
    "\n",
    "**Запишем определение производной под нашу задачу**\n",
    "\n",
    "Для начала вспомним определение производной для обычной функции одной переменной.Говорят, что у функции $f:  \\mathbb{R} \\to  \\mathbb{R}$ в точке $x$ есть производная $f'(x)$, если в этой точке функция представима в следующем виде для всех достаточно маленьких $\\mathrm{d}x$:\n",
    "\n",
    "$\\large f'(x) = \\lim\\limits_{\\mathrm{d}x \\to 0} \\frac{f(x + \\mathrm{d}x) - f(x)}{\\mathrm{d}x}$ перепишем в следующем виде:\n",
    "\n",
    "$\\large f(x + \\mathrm{d}x) = f(x) + f'(x)\\mathrm{d}x + o(\\mathrm{d}x)$\n",
    "\n",
    "То есть производная - это коэффициент, определяющий линейную часть приращения функции. Обобщим это на случай функций, работающих в конечномерных линейных пространствах с нормами. Говорят, что функция $f: \\mathbb{R}^n \\to \\mathbb{R}^m$ дифференцируема в точке $x$, если существует такой линейный оператор $L: \\mathbb{R}^n \\to \\mathbb{R}^m$, что для любых достаточно\n",
    "малых по нормеn $\\mathrm{d}x \\in \\mathbb{R}^n$ выполнено:\n",
    "\n",
    "$\\large f(x + \\mathrm{d}x) = f(x) + L[\\mathrm{d}x] + o(\\|\\mathrm{d}x\\|)$\n",
    "\n",
    "Можно показать, что если функция дифференцируема в точке $x$, то соответствующий линейный оператор определяется единственным образом. Будем обозначать его как $\\mathrm{d}f(x)$ и называть дифференциалом. Поскольку дифференциал - это линейный оператор, то в зависимости от размерностей пространств он может быть представлен как скалярное произведение $\\langle a_x, \\mathrm{d}x \\rangle$, умножение на матрицу $A_x \\mathrm{d}x$ или схожим образом. Тогда по аналогии с одномерным случаем вектор $a_x$ или матрица $A_x$ являются <<производными>> функции в точке $x$. Как мы знаем, для них есть специальные названия: $a_x$ называется градиентом, $A_x$ - матрицей Якоби.\n",
    "\n",
    "Когда мы работали с одномерными функциями, в большинстве случаев для поиска производных нам хватало небольшой таблицы со стандартными случаями и пары правил. Для случая векторных и матричных функций все эти правила можно обобщить, а таблицы дополнить специфическими функциями вроде определителя. Удобнее всего оказывается работать в терминах «дифференциала» - с ним можно не задумываться о промежуточных размерностях, а просто применять стандартные правила."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введём некоторые обозначения:\n",
    "\n",
    "$\\large \\textbf{При отображении вектора в число} f(x): \\mathbb{R}^n \\to \\mathbb{R}$         \n",
    "\n",
    "$\\large \\nabla_x f(x) = \\bigg[\\frac{\\partial f}{\\partial x_1}, \\dots, \\frac{\\partial f}{\\partial x_n} \\bigg]^T$\n",
    "\n",
    "Когда функция бьёт $\\textbf{из векторов в скаляры}$ $f(x) : \\mathbb{R}^n \\to \\mathbb{R}$, мы имеем дело с функцией нескольких переменных. Нам нужно взять производную по каждой из них и получить вектор производных, градиент\n",
    "\n",
    "$\\nabla_x f = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\ldots  \\\\ \\frac{\\partial f}{\\partial x_n} \\end{pmatrix}$\n",
    "\n",
    "Если умножить транспонированный градиент на вектор приращений, у нас получится дифференциал.\n",
    "\n",
    "$\\mathrm{d}{f(x)} = \\nabla_x f^T \\mathrm{d}{x} = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1}, & \\ldots,  & \\frac{\\partial f}{\\partial x_n} \\end{pmatrix} \\begin{pmatrix} \\mathrm{d}{x_1} \\\\  \\ldots  \\\\ \\mathrm{d}{x_n} \\end{pmatrix} = \\frac{\\partial f}{\\partial x_1} \\cdot \\mathrm{d}{x_1} + \\ldots +\\frac{\\partial f}{\\partial x_n} \\cdot \\mathrm{d}{x_n}.$\n",
    "\n",
    "При изменении $x_i$ на $\\mathrm{d}{x_i}$ функция будет при прочих равных меняться пропорционально соответствующей частной производной. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\textbf{При отображении матрицы в число} f(A): \\mathbb{R}^{n \\times m} \\to \\mathbb{R}$\n",
    "\n",
    "$\\large \\nabla_A f(A) = \\bigg(\\frac{\\partial f}{\\partial A_{ij}} \\bigg)_{i,j=1}^{n,m}$\n",
    "\n",
    "В таком случае нам надо найти производную функции по каждому элементу матрицы, то есть дифференциал будет выглядеть как \n",
    "\n",
    "$\\mathrm{d}{f(A)} = \\frac{\\partial f}{\\partial a_{11}} \\mathrm{d}{a_{11}} + \\ldots + \\frac{\\partial f}{\\partial a_{nm}} \\mathrm{d}{a_{nm}}$\n",
    "\n",
    "Его можно записать в компактном виде через след матрицы как\n",
    "\n",
    "$\\mathrm{d}{f(A)} = tr(\\nabla_A f^T \\mathrm{d}{A})$\n",
    "\n",
    "Вполне естественен вопрос - а почему это можно записать именно так?  Давайте попробуем увидеть этот факт на каком-нибудь простом примере. Пусть у нас есть две матрицы\n",
    "\n",
    "$A_{[2 \\times 3]} = \\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\end{pmatrix} \\qquad B_{[2 \\times 3]} = \\begin{pmatrix} b_{11} & b_{12} & b_{13} \\\\ b_{21} & b_{22} & b_{23} \\end{pmatrix}.$\n",
    "\n",
    "Посмотрим на то, как выглядит $tr(B^T \\mathrm{d}{A})$. Как это ни странно, он совпадает с дифференциалом\n",
    "\n",
    "$tr(B^T \\mathrm{d}{A}) = tr \\left( \\begin{pmatrix} b_{11} & b_{21} \\\\ b_{12} & b_{22} \\\\ b_{13} &  b_{23} \\end{pmatrix} \\begin{pmatrix} \\mathrm{d} a_{11} & \\mathrm{d} a_{12} & \\mathrm{d} a_{13} \\\\ \\mathrm{d} a_{21} & \\mathrm{d} a_{22} & \\mathrm{d} a_{23} \\end{pmatrix} \\right)$\n",
    "\n",
    "при произведении на выходе получаем матрицу размера $3 \\times 3$\n",
    "\n",
    "$\\begin{pmatrix} b_{11} \\mathrm{d} a_{11} +  b_{21} \\mathrm{d} a_{21} & b_{11} \\mathrm{d} a_{12} +  b_{21} \\mathrm{d} a_{22} & b_{11} \\mathrm{d} a_{13} +  b_{21} \\mathrm{d} a_{23} \\\\ b_{12} \\mathrm{d} a_{11} +  b_{22} \\mathrm{d} a_{21} & b_{12} \\mathrm{d} a_{12} +  b_{22} \\mathrm{d} a_{22} & b_{12} \\mathrm{d} a_{13} +  b_{22} \\mathrm{d} a_{23} \\\\ b_{13} \\mathrm{d} a_{11} +  b_{23} \\mathrm{d} a_{21} & b_{13} \\mathrm{d} a_{12} +  b_{23} \\mathrm{d} a_{22} & b_{13} \\mathrm{d} a_{13} +  b_{23} \\mathrm{d} a_{23} \\end{pmatrix}.$\n",
    "\n",
    "Когда мы берём её след, остаётся сумма элементов по диагонали. Это и есть требуемый дифференциал. Дальше мы периодически будем пользоваться таким приёмом. \n",
    "\n",
    "Например,  величину $||X-A||^2 = \\sum_{i,j} (x_{ij} - a_{ij})^2$ можно записать в матричном виде как  $tr((X-A)^T (X-A)).$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\textbf{При отображении вектора в вектор} f(x): \\mathbb{R}^n \\to \\mathbb{R}^m$\n",
    "\n",
    "$\\large \\mathfrak{J}_x = \\bigg(\n",
    "    \\frac{\\partial f_{i}}{\\partial x_{j}}\n",
    "\\bigg)_{i,j=1}^{n,m}$\n",
    "\n",
    "мы взаимодействуем с семейством функций. Например, если $n=1$ то у нас есть $m$ функций, каждая из которых применяется к $x$. На выходе получается вектор \n",
    "\n",
    "$\\begin{pmatrix} f_1(x) \\\\ f_2(x) \\\\ \\ldots  \\\\ f_m(x). \\end{pmatrix}$\n",
    "\n",
    "Если мы хотим найти производную, нужно взять частную производную каждой функции по $x$ и записать в виде вектора. Дифференциал также будет представлять из себя вектор, так как при приращении аргумента на какую-то величину изменяется каждая из функций \n",
    "\n",
    "$\\mathrm{d}{f(x)} = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x} \\\\ \\frac{\\partial f_2}{\\partial x} \\\\ \\ldots  \\\\ \\frac{\\partial f_m}{\\partial x} \\end{pmatrix} \\cdot \\begin{pmatrix} \\mathrm{d}{x}  \\end{pmatrix}  = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x} \\mathrm{d}{x} \\\\ \\frac{\\partial f_2}{\\partial x} \\mathrm{d}{x} \\\\ \\ldots  \\\\ \\frac{\\partial f_m}{\\partial x} \\mathrm{d}{x} \\end{pmatrix}$\n",
    "\n",
    "Тут мы умножаем каждую строчку из вектора размера $n \\times 1$ на столбец матрицы $1 \\times 1$. Если хочется, можно рассуждать об этом как о поэлементном умножении. Если $n > 1$, то аргументов на вход в такой вектор из функций идёт несколько, на выходе получается матрица \n",
    "\n",
    "$\\begin{pmatrix} f_1(x_1) & f_1(x_2) & \\ldots & f_1(x_n) \\\\ f_2(x_1)  & f_2(x_2) & \\ldots & f_2(x_n)  \\\\ \\ldots & \\ldots & \\ddots & \\ldots  \\\\ f_m(x_1)  & f_m(x_2) & \\ldots & f_m(x_n) \\end{pmatrix}$\n",
    "  \n",
    "Производной такой многомерной функции будет матрица из частных производных каждой функции по каждому аргументу\n",
    "\n",
    "$\\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\ldots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\frac{\\partial f_2}{\\partial x_1}  & \\frac{\\partial f_2}{\\partial x_2} & \\ldots & \\frac{\\partial f_2}{\\partial x_n}  \\\\ \\ldots & \\ldots & \\ddots & \\ldots  \\\\ \\frac{\\partial f_m}{\\partial x_1}  & \\frac{\\partial f_m}{\\partial x_2} & \\ldots & \\frac{\\partial f_m}{\\partial x_n} \\end{pmatrix}.$\n",
    "\n",
    "Дифференциал снова будет представлять из себя вектор\n",
    "\n",
    "$\\mathrm{d}{f(x)} =  \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\ldots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\frac{\\partial f_2}{\\partial x_1}  & \\frac{\\partial f_2}{\\partial x_2} & \\ldots & \\frac{\\partial f_2}{\\partial x_n}  \\\\ \\ldots & \\ldots & \\ddots & \\ldots  \\\\ \\frac{\\partial f_m}{\\partial x_1}  & \\frac{\\partial f_m}{\\partial x_2} & \\ldots & \\frac{\\partial f_m}{\\partial x_n} \\end{pmatrix} \\cdot  \\begin{pmatrix} \\mathrm{d}{x_1} \\\\ \\mathrm{d}{x_2} \\\\ \\ldots  \\\\ \\mathrm{d}{x_n} \\end{pmatrix} =  \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x_1} \\mathrm{d}{x_1} + \\frac{\\partial f_1}{\\partial x_2} \\mathrm{d}{x_2} + \\ldots + \\frac{\\partial f_1}{\\partial x_n} \\mathrm{d}{x_n}  \\\\ \\frac{\\partial f_2}{\\partial x_1} \\mathrm{d}{x_1} +  \\frac{\\partial f_2}{\\partial x_2} \\mathrm{d}{x_2} + \\ldots + \\frac{\\partial f_2}{\\partial x_n} \\mathrm{d}{x_n}  \\\\ \\ldots  \\\\ \\frac{\\partial f_m}{\\partial x_1} \\mathrm{d}{x_1} + \\frac{\\partial f_m}{\\partial x_2} \\mathrm{d}{x_2} + \\ldots + \\frac{\\partial f_m}{\\partial x_n} \\mathrm{d}{x_n} \\end{pmatrix}.$\n",
    "\n",
    "Мы хотим оценить, как функция изменяется по каждому из аргументов по\n",
    "отдельности. Поэтому производной функции по вектору будет вектор, по матрице — матрица. Теперь поупражняемся в дифференцировании:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные правила\n",
    "\n",
    "Приведенные правила можно вывести из определения, которое мы дали выше. Для вычисления большинства производных, которые возникают на практике, достаточно лишь небольшой таблицы стандартных производных и правил преобразования. Удобнее всего оказывается работать в терминах «дифференциала» — с ним можно не задумываться о промежуточных размерностях, а просто применять стандартные правила.\n",
    "\n",
    "1. $\\large \\mathrm{d} A = 0$ - если мы хотим посчитать дифференциал от матрицы $A$ и при этом эта матрица константа $A = con A$ (не зависит от переменных), тогда дифференциал равен 0.\n",
    "\n",
    "2. $\\large \\mathrm{d}(\\alpha X + \\beta Y) = \\alpha (\\mathrm{d}X) + \\beta (\\mathrm{d} Y)$\n",
    "\n",
    "3. $\\large \\mathrm{d}(XY) = (\\mathrm{d}X)Y + X(\\mathrm{d}Y)$\n",
    "\n",
    "4. $\\large \\mathrm{d}(X^T) = (\\mathrm{d}X)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 1</h3>\n",
    "\n",
    "Пусть $a \\in \\mathbb{R}^n$ - вектор параметров, а $x \\in \\mathbb{R}^n$ - вектор переменных. Необходимо найти производную их скалярного произведения по вектору переменных $\\nabla_x a^Tx$.\n",
    "\n",
    "<h4 align='center'>Решение:</h4>\n",
    "\n",
    "$\\large \\frac{\\partial}{\\partial x_i} a^Tx = \\frac{\\partial}{\\partial x_i}\\sum\\limits_j^n a_jx_j = a_i$ поэтому $\\nabla_x a^Tx = a$\n",
    "\n",
    "Заметим, что $a^Tx$ — это число, поэтому $a^Tx = x^Ta$, следовательно, $\\nabla_x x^Ta = a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Замечание:** $a^Tx$ здесь вектор $a$ мы транспонируем для того, чтобы можно было произвести умножения двух матриц. Получаем что матрица $a^T$ (вектор) имеет размерность $1 \\times n$, а матрица $x$ имеет размерность $n \\times 1$. Умножение матриц такой размерности идентично операции скалярного произведения векторов.\n",
    "\n",
    "**Запишем более подробное решение:**\n",
    "\n",
    "$\\large f(x) = a^T x$\n",
    "\n",
    "$\\large f(x) = \\sum\\limits_{j=1}^n a_jx_j$\n",
    "\n",
    "Производная по одной переменной записывается следующим образом: $\\large \\frac{\\partial f(x)}{\\partial x}$, а для вектора, соответсвенно, вот таким образом $\\large \\frac{\\partial f(x)}{\\partial x_i}$.\n",
    "\n",
    "Подставим функцию:\n",
    "\n",
    "$\\large \\frac{\\partial f(x)}{\\partial x_i} = \\frac{\\partial \\sum_{j=1}^n a_j x_j}{\\partial x_i} = \\frac{\\partial}{\\partial x_i} \\sum\\limits_{j=1}^n a_j x_j =$\n",
    "\n",
    "При дифференцировании, если $j \\ne i$, то ответ в сумме будет $0$, так мы $x_j$ и $x_i$ это две разные переменные, поэтому другая переменная будет считаться константой и всё зануляется. Значит, у нас отсаётся только:\n",
    "\n",
    "$\\large = \\frac{\\partial}{\\partial x_i} a_i x_i = a_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align='center'>Решение 2:</h4>\n",
    "\n",
    "$\\large \\nabla_x f = ?$\n",
    "\n",
    "Посчитаем линйное приращение функции в точке $x$. У нас произведение двух матриц, используем для этого правило\n",
    "\n",
    "$\\large \\mathrm{d}f = \\mathrm{d}(a^Tx) = (\\mathrm{d}a)^Tx + a^T (\\mathrm{d}x) = \\langle a, \\mathrm{d}x \\rangle$\n",
    "\n",
    "$(\\mathrm{d}a)^Tx$ - равно нулю, так как линейное приращение константы равно 0. Так как скалярное произведение аналогично следующей записе:\n",
    "\n",
    "$\\mathrm{d}{f(x)} = \\nabla_x f^T \\mathrm{d}{x} = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1}, & \\ldots,  & \\frac{\\partial f}{\\partial x_n} \\end{pmatrix} \\begin{pmatrix} \\mathrm{d}{x_1} \\\\  \\ldots  \\\\ \\mathrm{d}{x_n} \\end{pmatrix} = \\frac{\\partial f}{\\partial x_1} \\cdot \\mathrm{d}{x_1} + \\ldots +\\frac{\\partial f}{\\partial x_n} \\cdot \\mathrm{d}{x_n}$\n",
    "\n",
    "а производные - это фактически $a_i$ или же вектор $a$, поэтому в скалярном произвидении мы находим вектор всех производных или же градиент. Исходя из этого вывода, мы можем сказать что некий транспонированный вектор умноженный на приращение ($\\nabla_x f^T \\mathrm{d}{x}$) это и будет наша производная.\n",
    "\n",
    "$\\large \\nabla_x f = a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 2</h3>\n",
    "\n",
    "Пусть теперь $A \\in \\mathbb{R}^{n\\times n}$. Необходимо найти $\\nabla_x x^TAx$\n",
    "\n",
    "<h4 align='center'>Решение:</h4>\n",
    "\n",
    "$\\large \\frac{\\partial}{\\partial x_i} x^TAx = \\frac{\\partial}{\\partial x_i}\\sum\\limits_j x_j (Ax)_j = \\frac{\\partial}{\\partial x_i}\\sum\\limits_j x_j \\bigg(\\sum\\limits_k a_{jk}x_k\\bigg)=$ \n",
    "\n",
    "Результат перемножения $Ax$ - это вектор столбец, поэтому $x(Ax)$ - это перемножение вектора строки на вектор столбец. Дальше расписываем $Ax$ под знаком суммы и после раскрываем скобки:\n",
    "\n",
    "$\\large = \\frac{\\partial}{\\partial x_i} \\sum\\limits_{j,k} a_{jk} x_j x_k = $ \n",
    "\n",
    "Чтобы градиент данной сумму по $x_i$ получился не нулевой, необходимо чтобы $j=i$ или $k=i$.\n",
    "\n",
    "$\\large = \\sum\\limits_{j \\neq i} a_{ji} x_j + \\sum\\limits_{k \\neq i} a_{ik} x_k + 2a_{ii}x_i = \\sum\\limits_{j} a_{ji} x_j + \\sum\\limits_{k} a_{ik} x_k = \\sum\\limits_{j} (a_{ji} + a_{ij}) x_j$\n",
    "\n",
    "Поэтому $\\large \\nabla_x x^TAx = (A + A^T)x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align='center'>Решение 2:</h4>\n",
    "\n",
    "$\\large \\mathrm{d}f = \\mathrm{d}(x^TAx) = \\mathrm{d}(x^T)Ax + x^T\\mathrm{d}(Ax) = (\\mathrm{d}x)^TAx + x^T\\mathrm{d}(Ax) = (\\mathrm{d}x)^T Ax + x^T \\mathrm{d}(A)x + x^T A\\mathrm{d}(x) =$\n",
    "\n",
    "\n",
    "$\\large (\\mathrm{d}x)^T Ax = (Ax)^T \\mathrm{d}x = x^T A^T \\mathrm{d}x $ - так как после вычислений получится число, значит это скалярное произведение, мы можем местами поменять элементы и ничего не изменится. После можем раскрыть транспонирование поменяв элементы местами.\n",
    "\n",
    "$\\large x^T \\mathrm{d}(A)x = 0$ - Равняется нулю\n",
    "\n",
    "Запишем все вместе и вынесем $x^T$ слева за скобку, а $\\mathrm{d}x$ справа за скобку, получим:\n",
    "\n",
    "$\\large = x^T A^T \\mathrm{d}x + x^T A\\mathrm{d}x = x^T(A + A^T)\\mathrm{d}x$\n",
    "\n",
    "После необходимо выразить транспонированный градиент $\\nabla_x f^T \\mathrm{d}{x}$, так как мы знаем, что слева от $\\mathrm{d}x$ это наш градиент, только в транспонированном виде. Дальше выносим трансопнирование за скобку и приводим к виду скалярного произведения. Или можем транспонировать (по правилу) все до приращения и получить градиент:\n",
    "\n",
    "$\\large ((A + A^T)x)^T \\mathrm{d}x = \\langle (A + A^T)x, \\mathrm{d}x \\rangle$\n",
    "\n",
    "$\\large \\nabla_x x^TAx = (A + A^T)x$\n",
    "\n",
    "**Посчитаем вторую производную**\n",
    "\n",
    "$\\large \\nabla_x^2 x^TAx = A + A^T$ - так как мы находим градиент константы умноженный на $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 4</h3>\n",
    "\n",
    "Пусть $f(X) = a^TXAXa$, где $a \\in \\mathbb{R}^n, X \\in \\mathbb{R}^{n\\times n}.$ Необходимо найти производную $\\nabla_X f$.\n",
    "\n",
    "<h4 align='center'>Решение 2:</h4>\n",
    "\n",
    "Функция бьёт из матриц в скаляры. Дифференциал будет по своей размерности совпадать со скаляром. Производная будет размера матрицы\n",
    "\n",
    "$\\large \\mathrm{d}{f(X)} = \\mathrm{d}{(a^TXAXa)} = (\\mathrm{d}a)^T XAXa + a^T \\mathrm{d}(XAXa) = a^T \\mathrm{d}({X})AXa + a^T X\\mathrm{d}(AXa) = a^T\\mathrm{d}{(X)}AXa + a^TXA\\mathrm{d}{(X)}a$\n",
    "\n",
    "\n",
    "\n",
    "Теперь нам необходимо привести выражение к виуд $tr(X^T, \\mathrm{d}{X})$. Оба слагаемых, которые мы получаем после перехода к дифференциалу - скаляры. Мы хотим представить дифференциал в виде $tr(\\text{нечто} \\mathrm{d}{X})$. След скаляра (Матрица 1x1) - это снова скаляр (След матрицы 1x1 это и есть значение матрицы). Получается, что мы бесплатно можем навесить над правой частью нашего равенство знак следа и воспользоваться его свойствами\n",
    "\n",
    "$\\large \\mathrm{d}{f(X)} = \\mathrm{d}{(a^TXAXa)} = tr(a^T\\mathrm{d}{(X)}AXa) + tr(a^TXA\\mathrm{d}{(X)}a) = $ \n",
    "\n",
    "(Цикличное свойство следа) Как мы знаем, внутри следам мы можем матрицы циклически менять и след от этого не изменится:\n",
    "\n",
    "$\\large = tr(AXaa^T\\mathrm{d}{(X)}) + tr(aa^TXA\\mathrm{d}{(X)}) =$\n",
    "\n",
    "Так как функция следа от матрицы линейна, тогда два следа можно занести под один общий след:\n",
    "\n",
    "$\\large = tr(AXaa^T\\mathrm{d}{(X)} + aa^TXA\\mathrm{d}{(X)}) = tr((AXaa^T + aa^TXA)\\mathrm{d}{(X)})$\n",
    "\n",
    "Исходя из вида, которому мы приводи, необходимо только транспонировать результат слева от $\\mathrm{d}{(X)}$ и получить градиент:\n",
    "\n",
    "$\\large \\nabla_X f = (AXaa^T + aa^TXA)^T = aa^TX^TA^T + A^TXaa^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 5</h3>\n",
    "\n",
    "Пусть $f(x) = x x^T x$, где $x \\in \\mathbb{R}^n.$ Необходимо найти производную $\\nabla_x f$. \n",
    "\n",
    "<h4 align='center'>Решение 2:</h4> \n",
    "\n",
    "Функция бьёт из векторов в векторы.\n",
    "\n",
    "$\\large \\underset{[n \\times 1]}{f(x)} = \\underset{[n \\times 1]}{x} \\underset{[1 \\times n]}{x^T}  \\underset{[n \\times 1]}{x}.$\n",
    "\n",
    "Берём дифференциал \n",
    "\n",
    "\n",
    "$\\large \\mathrm{d}{f} = \\mathrm{d}{xx^Tx} = \\mathrm{d}(x)x^Tx + x\\mathrm{d}(x^Tx) = \\mathrm{d}({x})x^Tx + x \\mathrm{d}({x^T}) x + xx^T\\mathrm{d}({x})$\n",
    "\n",
    "В первом слагаемом пользуемся тем, что $x^Tx$ скаляр и его можно вынести перед дифференциалом. Этот скаляр умножается на каждый элемент вектора. \n",
    "\n",
    "Так как $(\\mathrm{d}x)^T$ это вектор приращений транспонированный, а $x$ какой-то другой вектор, получается, что скалярное умножение вектора на вектор, поэтому мы можем поменять их местами. Во втором слагаемом пользуемся тем, что $\\mathrm{d}{x^T} x$ скаляр и транспонируем его:\n",
    "\n",
    "$\\large x \\mathrm{d}({x^T})x = x (\\mathrm{d}x)^Tx = x x^T\\mathrm{d}x$\n",
    "\n",
    "Получаем выражение где $\\mathrm{d}x$ стоит справа: \n",
    "\n",
    "$\\large x^Tx\\mathrm{d}(x) + x x^T\\mathrm{d}x + xx^T\\mathrm{d}({x})$\n",
    "\n",
    "Дальше мы захотим вынести дифференциал за скобку, чтобы не испортить матричное сложение, подчеркнём факт этого перемножения на каждый элемент единичной матрицей. \n",
    "\n",
    "$\\large \\mathrm{d}{f(x)} = \\underset{[1 \\times 1]}{x^Tx} \\underset{[n \\times n]}{I_n} \\underset{[n \\times 1]}{\\mathrm{d}{x}} + x x^T \\mathrm{d}{x} + xx^T\\mathrm{d}{x} = (x^Tx I_n + 2 x x^T)\\mathrm{d}{x}.$\n",
    "\n",
    "$\\large \\nabla_x f = x^Tx I_n + 2 x x^T$\n",
    "\n",
    "Обратите внимание, что без единичной матрицы размерности у сложения поломаются. Получается, что наша производная выглядит как $\\mathfrak{J} = x^Tx I_n + 2 x x^T$\n",
    "\n",
    "Найдём несколько табличных производных, которыми мы дальше будем активно пользоваться: производную обратной матрицы, определителя и следа. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 6</h3>\n",
    "\n",
    "Пусть  $f(X) = X^{-1},$ где $X \\in \\mathbb{R}^{n\\times n}.$  Необходимо найти $\\nabla_X f(X)$. \n",
    "\n",
    "<h4 align='center'>Решение 2:</h4> \n",
    "\n",
    "$\\large f(X) : \\mathbb{R}^{n \\times n} \\to \\mathbb{R}^{n \\times n}$ так как у нас $n^2$ выходов и входов, тогда необходимо посчитать производную по всем входам и выходам, а это  4-х мерный тензор.\n",
    "\n",
    "Вспомним, что производная константы равна нолю. Обратная матрица определяется как $X^{-1} \\cdot X = I_n,$ где $I_n$ - единичная матрица. Берём дифференциал с обеих сторон нашего равенства \n",
    "\n",
    "$\\large \\mathrm{d}({X^{-1}}) X + X^{-1} \\mathrm{d}({X}) = \\mathrm{d}({I_n}) = 0$\n",
    "\n",
    "Разнесем по разыне стороны:\n",
    "\n",
    "$\\large \\mathrm{d}({X^{-1}})X = - X^{-1} \\mathrm{d}(X)$\n",
    "\n",
    "Выразим дифференциал обратной матрицы и домножим обе стороны на $X^{-1}$:\n",
    "\n",
    "$\\large \\mathrm{d}{X^{-1}} = - X^{-1} \\mathrm{d}(X)X^{-1}$\n",
    "\n",
    "\n",
    "Везде, где мы будем встречать дифференциал обратной матрицы, мы будем использовать это значение.  Обратите внимание, что обратная матрица как функция отображает матрицы в матрицы. Эта клетка в табличке производных осталась нами незаполненной. Тем не менее мы можем использовать ту же самую технику с дифференциалами. Если где-то нам надо будет посчитать дифференциал обратной матрицы, мы будем поставлять туда полученную выше формулу. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 7</h3>\n",
    "\n",
    "Пусть $X \\in \\mathbb{R}^{n\\times n}$. Необходимо найти $\\nabla_X \\det X$.\n",
    "\n",
    "<h4 align='center'>Решение 2:</h4>\n",
    "\n",
    "$\\large f(X) : \\mathbb{R}^{n \\times n} \\to \\mathbb{R}$\n",
    "\n",
    "Т.Лапласа:\n",
    "\n",
    "$\\large \\det X = \\sum\\limits_{k=1}^n (-1)^{i + k} X_{ik} M_{ik}$\n",
    "\n",
    "Что под знаком суммы зависит от $ij$ элемента матрицы $X$? $X_{ik}$ зависит, когда $k = j$. Минор не зависит от $ij$ элемента матрицы $X$, так как мы в миноре вычеркиваем $i$ строку и $j$ столбец, поэтому минор это константа относительно $X_{ij}$.\n",
    "\n",
    "Определитель - это функция, которая бьёт из матриц в скаляры. Воспользуемся теоремой Лапласа о разложении определителя по строке:\n",
    "\n",
    "$\\large \\frac{\\partial}{\\partial X_{ij}} \\det X = \\frac{\\partial}{\\partial X_{ij}}\\bigg[\\sum\\limits_{k=1}^n (-1)^{i+k}X_{ik}M_{ik}\\bigg] = (-1)^{i+j}M_{ij},$\n",
    "\n",
    "где $M_{ik}$ - дополнительный минор матрицы $X$. Также вспомним формулу для элементов обратной матрицы\n",
    "    \n",
    "$\\large (X^{-1})_{ij} = \\frac{1}{\\det X}(-1)^{i+j}M_{ji}$\n",
    "    \n",
    "Подставляя выражение для дополнительного минора, получаем ответ $\\nabla_X \\det X = (\\det X) X^{-T}$. При этом, так как функция бьёт из матриц в скаляры дифференциал можно записать как  $\\mathrm{d}({ \\det X}) = tr(\\det (X) X^{-1} \\mathrm{d}{X}).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 7</h3>\n",
    "\n",
    "Вспомним, зачем мы хотели научиться дифференцировать. В общем случае мы имеем выборку $\\{(x_i, y_i)\\}_{i=1}^\\ell$, $x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R} \\; i = \\overline{1, \\ell}$, и хотим найти наилучшие параметры модели $a(x) = \\langle w, x \\rangle$ с точки зрения минимизации функции ошибки.\n",
    "\n",
    "$\\large Q(w, X) = ||Xw-y||^{2}$\n",
    "\n",
    "Необходимо найти $\\nabla_w Q(w)$.\n",
    "\n",
    "Здесь $X\\in \\mathbb{R}^{\\ell \\times d}$ — матрица <<объекты-признаки>>\\ для обучающей выборки, $y~\\in~\\mathbb{R}^\\ell$ — вектор значений целевой переменной на обучающей выборке, $w \\in \\mathbb{R}^d$ - вектор параметров.\n",
    "\n",
    "\n",
    "<h4 align='center'>Решение 2:</h4>\n",
    "\n",
    "Выпишем дифференциал функции ошибки по $w$, для этого необходимо переписать функцию в следующем виде:\n",
    "\n",
    "$\\large Q(w) = (y - Xw)^T(y - Xw)$\n",
    "\n",
    "$\\large \\mathrm{d}_w Q = \\mathrm{d}_w[(y - Xw)^T(y - Xw)] =$\n",
    "\n",
    "$\\large = \\mathrm{d}_w[(y - Xw)^T] (y - Xw) + (y - Xw)^T\\mathrm{d}_w[(y - Xw)] =$ \n",
    "\n",
    "Как мы преобразовали $\\mathrm{d}_w[(y - Xw)^T]$ к виду $\\mathrm{d}_w[(-Xw)^T]$? Здесь $y$ является констатой по отношению к $w$, по которому считается градиент.\n",
    "\n",
    "Транспонируем выражение внутри, используем правило суммы\n",
    "\n",
    "$\\mathrm{d}_w[(y - Xw)^T] = \\mathrm{d}_w[(-w^T X^T + y^T)] = \\mathrm{d}(-w^TX^T) + \\mathrm{d}(y^T) = \\mathrm{d}(-w^TX^T)$\n",
    "\n",
    "И если в выражении $\\mathrm{d}_w[(-Xw)^T]$ транспонировать $(-Xw)^T$ мы получим $\\mathrm{d}(-w^TX^T)$, что и аналогично записи выше.\n",
    "\n",
    "$\\large = \\mathrm{d}_w[(-Xw)^T] (y - Xw) + (y - Xw)^T  \\mathrm{d}_w[(-Xw)] =$ \n",
    "\n",
    "\n",
    "\n",
    "$\\large = \\mathrm{d}_w[(-Xw)^T] (y - Xw) - (y - Xw)^TX\\mathrm{d} w =$ \n",
    "\n",
    "$\\large = - (\\mathrm{d} w)^T X^T (y - Xw) - (y - Xw)^TX\\mathrm{d} w = $\n",
    "\n",
    "Транспонируем левую часть. Тут мы воспользовались тем, что $ \\mathrm{d} w^T X^T (y - Xw)$ это скаляр и его можно транспонировать. Получаем, что слева и справа два подобных слогаемых\n",
    "\n",
    "$\\large = -2 (y - Xw)^TX \\mathrm{d} w =$\n",
    "\n",
    "Так как функция бьёт из векторов в скаляры $\\large f(X) : \\mathbb{R}^{n} \\to \\mathbb{R}$. Нам необходимо представить полученный дифференциал в виде скалярного произведения и посмотреть на что умножается $\\mathrm{d} w$, чтобы найти градиент:\n",
    "\n",
    "$\\large = \\langle -2X^T(y-Xw), \\mathrm{d}w \\rangle$, отсюда следует, что\n",
    "\n",
    "$\\large \\nabla_w Q = -2X^T(y-Xw) = 2X^T(Xw - y)$\n",
    "\n",
    "Приравняем производную к нулю, чтобы найти минимум для $w$. Получается система уравнений\n",
    "\n",
    "$\\large 2X^T(Xw - y) = 0$\n",
    "\n",
    "$\\large 2X^TXw -2X^Ty = 0$\n",
    "\n",
    "$\\large 2X^TXw = 2X^Ty$\n",
    "\n",
    "$\\large X^TXw = X^Ty$\n",
    "\n",
    "Домножаем на обратную матрицу $(X^T X)^{-1}$\n",
    "\n",
    "$\\large w = (X^TX)^{-1} X^Ty$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
