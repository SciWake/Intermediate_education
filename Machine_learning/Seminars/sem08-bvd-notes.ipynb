{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494c268f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Семинар 8</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. Разложение на смещение и разброс</h1>\n",
    "\n",
    "Имеется некоторый метод обучения $\\mu:(\\mathbb{X} \\times \\mathbb{Y})^\\ell \\to \\mathbb{A}$ - это некоторая функция, которая на вход принимает обучающую выборку, набор пар - объект, ответ, которых $\\ell$ штук и выдает некоторую модель. Где $\\mathbb{X} \\times \\mathbb{Y}$ - множество всех обучающих выборок, $\\mathbb{A}$ - семейство моделей.\n",
    "\n",
    "Метод обучения выдает какую-то модель по обучающей выборке, если измерять ошибку моделей через квадрат отклонения $L(y, a) = (y-a)^2$, тогда можно показать, что ошибка метода обучения складывается из 3-х слогаемых:\n",
    "\n",
    "\n",
    "$L(\\mu) = \n",
    "\\mathbb{E}_{x, y}\\bigl[\\mathbb{E}_{X}\\bigl[ (y - \\mu(X)(x))^2 \\bigr]\\bigr] = \n",
    "    \\underbrace{\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{шум}} + \\underbrace{\\mathbb{E}_{x}\\bigl[(\\mathbb{E}_{X}[\\mu(X)(x)] - \\mathbb{E}[y|x] )^2\\bigr]}_{\\text{смещение}} +\n",
    "    \\underbrace{\\mathbb{E}_{x}\\bigl[\\mathbb{E}_{X}\\bigl[(\\mu(X)(x) - \\mathbb{E}_{X}[\\mu(X)(x)] )^2\\bigr]\\bigr]}_{\\text{разброс}},$\n",
    "\n",
    "\n",
    "* $\\mu(X)$ - алгоритм, обученный по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$;\n",
    "\n",
    "* $\\mu(X)(x)$ - ответ алгоритма, обученного по выборке $X$, на объекте $x$;\n",
    "\n",
    "* $\\mathbb{E}_{X}$ - мат. ожидание по всем возможным выборкам;\n",
    "\n",
    "* $\\mathbb{E}_{X}[\\mu(X)(x)]$ - <<средний>> ответ алгоритма, обученного по всем возможным выборкам $X$, на объекте $x$.\n",
    "\n",
    "С помощью этой формулы мы можем анализировать свойства алгоритма обучения модели $\\mu$, если зададим вероятностную модель порождения пар $p(x, y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb527c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">1.1 Разложение для линейной модели</h2>\n",
    "\n",
    "Чтобы лучше понять смысл трех компонент, входящих в разложение, рассмотрим модельный пример одномерной линейной регрессии.\n",
    "\n",
    "**Алгоритм обучения $\\mu$** \n",
    "\n",
    "В одномерной линейной регрессии зависимость целевого признака $y$ от объекта $x$ моделируется с помощью примитивной линейной функции $y = kx$. Тогда, модель принимает вид \n",
    "\n",
    "$a(x) = kx \\quad x \\in \\mathbb{R}$, \n",
    "\n",
    "если имеется конкртная обучающая выборка, тогда можно записать среднеквадратичную ошибку и найти оптимальный коэффициент $k$. \n",
    "\n",
    "Оптимальный параметр $k$ находится по выборке $X = \\{(x_1, y_1), \\dots (x_\\ell, y_\\ell)\\}$ минимизацией $\\text{MSE}= \\sum_{i=1}^\\ell (y_i - k x_i)^2$. В результате получается следующий алгоритм $\\mu(X)$ (см. семинар по линейной регрессии):\n",
    "\n",
    "$$\\mu(X)(x) = k(X ) \\,x, \\quad k(X) = \\frac{\\sum_i x_i y_i}{\\sum_i x_i^2}.$$\n",
    "\n",
    "Где $\\mu(X) = k(X)x$ - модеь с некоторым коэффициентом $k$, который зависит от выборки умноженное на $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852da4a",
   "metadata": {},
   "source": [
    "**Модель порождения данных.**\n",
    "\n",
    "Будем считать, что объекты $x$ генерируются из нормального распределения $x \\sim p(x) = \\mathcal{N}(0, \\sigma_1^2)$. Правильный ответ на объекте $x$ определяется зашумленной функцией $f(x)$: $y = f(x) + \\varepsilon$, где распределение $\\varepsilon \\sim p(\\varepsilon) = \\mathcal{N}(0, \\sigma_2^2)$. Иными словами, $y \\sim p(y|x) = \\mathcal{N}(f(x), \\sigma_2^2)$. \n",
    "    \n",
    "Выборка $X$ составляется из $\\ell$ независимых пар $(x_i, y_i)$. Мы будем рассматривать два простых частных случая: $f(x) = ax$, когда модель зависимости отвечает искомой зависимости, и $f(x)$ - четная функция, т. е. $f(-x) = f(x)$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfdc9b5",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#2E8B57\">Задача № 1</h3>\n",
    "\n",
    "Найдите шумовую компоненту для одномерной линейной регрессии.  \n",
    "\n",
    "<h4 align='center'>Решение:</h4>\n",
    "\n",
    "Так как распределение $p(y|x)$ нормальное, для него легко вычислить мат. ожидание:\n",
    "\n",
    "$\\mathbb{E}[y|x] = f(x)$\n",
    "\n",
    "Мы знаем, что шум записывается следующим образом:\n",
    "\n",
    "$\\mathbb{E}_{x, y}\\bigl[(y - \\mathbb{E}[y|x] )^2\\bigr] = \n",
    "\\mathbb{E}_{x, \\varepsilon}\\bigl[(f(x) + \\varepsilon - f(x) )^2\\bigr] = \n",
    "\\mathbb{E}_{\\varepsilon} \\varepsilon^2 = \\mathbb{D}\\varepsilon + \\bigl(\\mathbb{E}\\varepsilon\\bigr)^2 = \\sigma_2^2 + 0 = \\sigma_2^2.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944084ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
