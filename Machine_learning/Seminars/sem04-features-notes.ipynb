{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a905247f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Предобрадотка данных</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">3. Обработка категориальных признаков</h1>\n",
    "\n",
    "<h2 style=\"color:#008B8B\">3.2 One-hot encoding</h2>\n",
    "\n",
    "Если у признака имеется много категорий и среди них имеются редкие, тогда возникает множество проблем.\n",
    "\n",
    "Решается данная проблема следующим образом:\n",
    "\n",
    "* **Trash bucket** - соеденяем редкие категории в одну.\n",
    "\n",
    "* **Хеширование** - делаем хеш функцию h, которая множество категорий признака переводит в другое множество, которое меньше по своей мощности.\n",
    "\n",
    "$\\large C = \\{c_1, \\ldots, c_m\\}$ - множество значений признака\n",
    "\n",
    "$\\large h: C \\to \\{1, \\ldots, K\\}$ где $K < |C|$\n",
    "\n",
    "Если правильно подобрать $K$, тогда соеденение признаком посредством хеширования не испортит модель, новый признак будет информативен так же, как они в раздельности. После хеширования могут возникнуть коллизии, но они не будут оказывать негативное воздействие.\n",
    "\n",
    "**Random projections** \n",
    "\n",
    "Имеется набор признаков $x$. Гененрируем набор весов из нормлаьного распределения $w \\sim \\mathcal{N}(0, 1)$, после добавляем новый признак $\\langle w, x \\rangle$. И так можно повторить много раз, если у нас есть миллион признаков, мы генерируем много векторов весов такой же размерности и заменяем старые признаки на скалярное произведение вектора весов на старые признаки.\n",
    "\n",
    "Данный метод позвоялет понижаеть размерность без большого влияния на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede2c34",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">3.3 Кодирование с учётом целевой переменной</h2>\n",
    "\n",
    "### Для бинарной классификации\n",
    "\n",
    "$\\large \\mathbb{Y} = \\{1, 0\\}$\n",
    "\n",
    "$\\large g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$\n",
    "\n",
    "где $f_j(x_i)$ - $j$-й признак $i$-го объекта, $y_i$ - класс $i$-го объекта.\n",
    "\n",
    "Здесь мы заменяем $j$-й категориальный признак на числовой. В числителе мы считаем количество объектов положительного класса, в знаменателе общее количество объектов признака, значит, мы получим долю объектов положитлеьного класса. Для отрицательного класса, мы можем найти долю как $1 - g_j$. \n",
    "\n",
    "Мы получаем для каждой категории вероятность, того что объект с этой категорией относится к положительному классу.\n",
    "\n",
    "Если у некоторого признака все объекты категории положитлеьные, это указывает на то, что скорее всего объект данной категории будет положительным.\n",
    "\n",
    "### Для многоклассовой классификации\n",
    "\n",
    "$\\large \\mathbb{Y} = \\{1, \\ldots, K\\}$\n",
    "\n",
    "Отметим, что эту формулу легко перенести как на случай многоклассовой классификации (в этом случае будем считать K признаков, по одному для каждого класса, и в числителе будет подсчитывать долю объектов с заданной категорией и с заданным классом), так и на случай регрессии (будем вычислять среднее значение целевой переменной среди объектов данной категории).\n",
    "\n",
    "$\\large g_{jk}(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = k]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$\n",
    "\n",
    "В числителе суммируем по всем объектам, ищем объекты с такой же категорией как у $\\ell$ объекта и средни них считаем объекты только $k$-го класса. И делим на количество объектов данной категории. Тем самым, мы каждую категорию кодируем распределением на $K$ исходов, которое говорит о том, какая вероятность при некой категории получить свой класс.\n",
    "\n",
    "### Для регрессии\n",
    "\n",
    "$\\large \\mathbb{Y} = \\mathbb{R}$\n",
    "\n",
    "Мы считаем среднее значение целевой переменной внутри данной категории.\n",
    "\n",
    "$\\large g_{j}(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]y_i}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f426e9",
   "metadata": {},
   "source": [
    "### Переобучение\n",
    "\n",
    "Напряму считать новый признак под данным формулам будет плохой идеей, так как модель может переообучиться. Если у некоторой категории признака целевая переменная будет все время принимать один класс (у данной категории оказалось, например, два объекта для которых целева переменная совпала), тогда значение $g_j$ будет равно значению целевой переменной. Тем самым, модель может подумать что в столбец стоит ответ. Так как значение целевой переменной было оценено малым количеством объектов, тогда данная оценка будет ненадежной, смешненной и так как модель доверяет данной оценке, она может переобучиться. \n",
    "\n",
    "### Борьба с переобучением\n",
    "\n",
    "И нам необходимо, чтобы модель могла опираться на значение счетчика только в случае высокой уверенности того, что оценка внутри данной категории скорее всего соответствует классу целевой переменной.\n",
    "\n",
    "$\\large g_j(x, X)\n",
    "=\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "        +\n",
    "        \\frac{C}{\\ell}\n",
    "        \\sum_{i=1}^{\\ell}\n",
    "        [y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "    [f_j(x) = f_j(x_i)] + C\n",
    "}$\n",
    "\n",
    "где $C$ – коэффициент, отвечающий за баланс между средним значением по категории и глобальным средним значением (гиперпараметр).\n",
    "\n",
    "Предаоложим, что C = 100 и всего один объект в некоторой категории. Если значение целевой переменной равно 1, тогда классическая формула $g_j$ (без правой) вернет 1, так как в числителе и знаменателе будут 1. Получается что правая часть будет оказывать воздействи на результат:\n",
    "\n",
    "$\\large \\frac{C}{\\ell} \\sum_{i=1}^{\\ell} [y_i = +1]$ - доля положительный объектов в выборке умноженное на $C$. \n",
    "\n",
    "Так как в знаменателе мы делим на $C$, тогда $C$ просто сокращаются и данная дробь будет близка к доле положительных объектов в выборке. Чем больше в категории будет объектов с положительной целевой переменной (две суммы слева), тем больше влияение на результут дроби они будут оказывать, так как поправка $C$ будет вносить меньший вклад.\n",
    "\n",
    "Если мало объектов в данной категории, тогда $g_j(x, X) \\approx \\frac{1}{\\ell} \\sum_{i=1}^{\\ell} [y_i = +1]$ будет примерно равно доли положительных объектов в выборке. Тогда модель не сможет переобучиться под такое значение, так как доля положительных объектов в выборке не содержит информации о объекте и модель не сможет узнать ответ на конкретном объекте.\n",
    "\n",
    "А если объекту много, тогда $g_j(x, X) \\approx \\text{классической формуле}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678098b",
   "metadata": {},
   "source": [
    "### Почему выходы других моделей приводят к переобучению?\n",
    "\n",
    "$g_j(x, X)$ является простой моделью, так как это число посчитанное с учетом целевой переменной. И тогда $a(x)$, которая обучается на новых признаках будет иметь выходы другой простой модели. \n",
    "\n",
    "Почему если среди признаков есть выходы другой модели? Если мы уверены что признаки имееют одинаковый смысл как обучающей так и на тестовой выборке, например, цвет автомобиля там и там будет иметь один смысл. Но этот признак на основе выхода модели может изменить свой смысл и если модель $g_j(x, X)$ будет переобучена, тогда качество на обучающей выборке будет выше чем на тестовой. \n",
    "\n",
    "Когда модель будет обучаться на обучающей выборке, модель заметит что признак оказывает большое влияние на предсказание и модель будет на него пологаться. Но когда модель будет применена на тестовой выборке, модель прежде будет уверена что это признак является хорошим, но так как выход простой модели изменил смысл признака. Почему смысл признака был изменен? Так как мы обучали его на обучающей выборке с известными целевыми переменными, а на тренировочной выборке нам целевые переменные неизвестны, тогда мы заменяем категории признаков используя уже обученную модель, котора могла подогнаться под обучающую выборку. Именно поэтому мы подбираем $C$ по тренировочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53bc68",
   "metadata": {},
   "source": [
    "### Сглаживание\n",
    "\n",
    "Можно немного модифицировать формулу,\n",
    "чтобы сила регуляризации зависела от объёма данных по конкретной категории:\n",
    "\n",
    "\n",
    "$ g_j(x, X)\n",
    "=\n",
    "\\lambda \\left( n(f_j(x)) \\right)\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "    [f_j(x) = f_j(x_i)]\n",
    "}\n",
    "+\n",
    "\\left( 1 - \\lambda \\left( n(f_j(x)) \\right) \\right)\n",
    "\\frac{1}{\\ell}\n",
    "\\sum_{i = 1}^{\\ell}\n",
    "    [y_i = +1]$\n",
    "\n",
    "где $n(z) = \\sum_{i = 1}^{\\ell} [f_j(x_i) = z]$ - число объектов категории $z$, \n",
    "\n",
    "$n(f_j(x))$ - число объектов данной категорией в выборке.\n",
    "\n",
    "$\\lambda(n)$ - некоторая монотонно возрастающая функция, дающая значения из отрезка $[0, 1]$.\n",
    "\n",
    "Примером может служить $\\lambda(n) = \\frac{1}{1 + \\exp(-n)}$.\n",
    "Если грамотно подобрать эту функцию, то она будет вычищать значение целевой переменной из редких категорий и мешать переобучению. \n",
    "\n",
    "Если категория будет большой по размеру функция будет отдавать предпочтени первому слогаемому, если маленькая тогда второму. Идея заключается в том, что чем меньше значений в категории, тем значение счетчика будет больше сдвигать к среднему значению класса по всей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86090cf1",
   "metadata": {},
   "source": [
    "### Зашумление\n",
    "\n",
    "Можно посчитать новые признаки по базовой формуле (3.1), а затем просто добавить к каждому значению случайный шум (например, нормальный). Это\n",
    "действительно снизит уровень корреляции счётчиков с целевой переменной. Проблема в том, что это делается за счёт снижения силы такого признака, а значит, мы ухудшаем итоговое качество модели. Поэтому важно подбирать дисперсию шума, чтобы соблюсти баланс между борьбой с переобучением и предсказательной силой счётчиков.\n",
    "\n",
    "$\\large \\tilde{g}_{j}(x, X) = g_{j}(x, X) +  \\mathcal{N}(\\mu, \\sigma^2)$,\n",
    "\n",
    "где  $\\mathcal{N}(\\mu, \\sigma^2)$ — нормальное распределение\n",
    "со средним $\\mu = 0$ и дисперсией $\\sigma^2$. \n",
    "\n",
    "\n",
    "Здесь необходимо правильно подобрать $\\sigma^2$, так чтобы на маленьких категориях сильно зашумлял признак, а на больших не очень, а это возможно если $\\sigma^2 (f_j(x))$ зависит от категорий на данном объекте, что весьма сложная задача.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60122b0c",
   "metadata": {},
   "source": [
    "### Кросс-валидация\n",
    "\n",
    "Разделяем обучающую выборку на $K$ блоков. Возьмем $K=3$, если необходимо посчитать счетчики для третьего блока, тогда мы берем первый и второй блок, по ним считаем статистику:\n",
    "\n",
    "$\\large \\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]$ - количество объектов данной категории для положительного класса\n",
    "\n",
    "$\\large \\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]$ - общее количество объектов данной категории\n",
    "\n",
    "И счетчики на третьем блоке мы вычисляем на основе статистик посчитаных на первом и втором блоке, то есть подставляем эти статистики в формулу $g_j$. Получаем, что счетчи посчитанный на третьем блоке не использует информацию о целевой переменной, а значит модели будет сложнее переобучиться. Аналогично можем посчитать остальные блоки.\n",
    "\n",
    "**А что если у нас много категорий и по многим категориям мало объектов?**\n",
    "\n",
    "Если имеются категории, где мало объектов, например два объекта, тогда один объект может попасть в первый блок, а другой в третий. Что получается? Счетчик для первых двух блоков будет равен значению целевой переменной на этой категории и в третий блок мы запишем его, то есть запишем знацение целевой переменной, дадим модели ответ. Для решения этой проблемы необходимо использовать улучшения счетчика которые мы придумали или же (Trash bucket/Хеширование).\n",
    "\n",
    "**Как считать счетчики для тестовой выборки?**\n",
    "\n",
    "Для тестовой выборки мы считаем статистики по всей обучающей выборке и рассчитывает счетчики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4483e",
   "metadata": {},
   "source": [
    "### Кросс валидация и кросс валидация счетчиков\n",
    "\n",
    "Если мы рзбили выборку на $K$ блоков для кросс валидации модели, возьмем $K = 3$, где первы два блока выступаю для обучения модели (1-я часть рисунка).\n",
    "\n",
    "<img src=\"img/4_1.png\">\n",
    "\n",
    "Чтобы обучить модель на первых двух блоках, мы должны посчитать там значени счетчиков. Мы берем и разбиваем первый блок на 3 части и выполняем действия аналогичные тому, как мы считали это выше для 3-го блока. Теперь аналогично  разбиваем второй блок на 3 части и считаем счетчики для этого блока.\n",
    "После мы можем обучить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb28ea",
   "metadata": {},
   "source": [
    "### Кодирование по времени\n",
    "\n",
    "Зададим порядок для обучающей выборки. И когда мы будем считать счетчики на екотором объекте, то мы бдуем использовать информацию об объектах, которые расположены до текщуего.\n",
    "\n",
    "$\\large g_j(x_k, X)\n",
    "=\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{k - 1}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{k - 1}\n",
    "        [f_j(x) = f_j(x_i)]}$\n",
    "\n",
    "Получается, что счетчики на каждом объекте учитывают информацию о целевой переменной только на части объектов. Причем, чем позже стоит объект в выборке, тем большую часть выборки захватывает статистика по которой считаются счетчики для объекта. \n",
    "\n",
    "Это хорошо позволяет бороться с переобучением, так как счетчики будут рассчитаны хорошо на последних объектах, поэтому на большей части объектов этот признак будет оказывать не очень сильное влияние и это будет мешать модели переобучиться на нем.\n",
    "\n",
    "Данный метод хорошо работает если мы несколько раз отсортируем выборку (100 раз) и по каждому порядку посчитаем такие счетчики (получим 100 признаков).\n",
    "\n",
    "**Почему данному методу сложнее переобучиться?**\n",
    "\n",
    "Если же в методах выше, счетчик для определенной категории принимал строго одно значение, то при с кодирование по времени у одной категории счетчик может равнятся разным значеним, так как мы перемещаемся по выборке. Из-за этого модель не сможет понять закономерность того, что счетчик это и есть ответ целевой переменной.\n",
    "\n",
    "Даже в примере, когда в категории два объекта, счетчик мог передать ответ, так как мы считали значение счетчика по одному объекту. В этом случае на первом объекте значение счетчика будет равно 0, так как выше нет объектов данной категории, а на втором объекте мы получим значение первого объекта, например один. Получаем два значения у одной категории, из-за чего модель не определит значение целевой переменной и модель будет учитывать другие признаки тоже, что на и необходимо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3489e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">4. Извлечение признаков из текстов</h1>\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.1 Bag-of-words</h2>\n",
    "\n",
    "Простой способ заключается в подсчёте, сколько раз встретилось каждое слово\n",
    "в тексте. Получаем вектор длиной в количество уникальных слов, встречающихся во всех объектах выборки. В таком векторе много нулей, поэтому его удобнее хранить в разреженном виде (где каждому признаку соответствует то, сколько раз $N$-ое слово встречается в тексте). Такой способ представления текстов называют мешком слов (так как мы убрали порядок и не можем восстановить порядок слов).\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.2 TF-IDF</h2>\n",
    "\n",
    "Считаем два показателя для текста:\n",
    "\n",
    "**TD (Term Frequency)** - количество вхождений слова в отношении к общему числу слов в тексте, другими словаи это доля некого слова в документе:\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$\n",
    "\n",
    "где $n_{td}$ \" - количество вхождений слова $t$ в текст $d$\n",
    "\n",
    "$\\sum_{t \\in d} n_{td}$ - общее количество слов в документе.\n",
    "\n",
    "**IDF (Inverse Document Frequency)**:\n",
    "\n",
    "Некторые слова которые встречаются в каждом документе и если у нас в тексте встретилось слово \"но\", то оно скорее всего ничего не значит, а слово которое встречается редко имеет большое значение. И для этого мы можем добавить в признак информацию о том, насколько слово характерно для определенного документа.\n",
    "\n",
    "$$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$\n",
    "\n",
    "где $D$ - набор всех документов,\n",
    "\n",
    "В числителе у нас число документов\n",
    "\n",
    "а в числителе $\\left| \\{d\\in D: t \\in d\\} \\right|$ \" - количество текстов в коллекции, содержащих слово $t$, другими словами это число документов, в которых встречается данное слово. \n",
    "\n",
    "Тем самым чем более уникально слово, тем выше будет idf.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "\n",
    "$$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.3 N-граммы</h2>\n",
    "\n",
    "В этом случае словарь состоить не только из отдельных слов, но из словосочетаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
