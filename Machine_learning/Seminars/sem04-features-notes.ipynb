{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a905247f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Предобрадотка данных</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">3. Обработка категориальных признаков</h1>\n",
    "\n",
    "<h2 style=\"color:#008B8B\">3.2 One-hot encoding</h2>\n",
    "\n",
    "Если у признака имеется много категорий и среди них имеются редкие, тогда возникает множество проблем.\n",
    "\n",
    "Решается данная проблема следующим образом:\n",
    "\n",
    "* **Trash bucket** - соеденяем редкие категории в одну.\n",
    "\n",
    "* **Хеширование** - делаем хеш функцию h, которая множество категорий признака переводит в другое множество, которое меньше по своей мощности.\n",
    "\n",
    "$\\large C = \\{c_1, \\ldots, c_m\\}$ - множество значений признака\n",
    "\n",
    "$\\large h: C \\to \\{1, \\ldots, K\\}$ где $K < |C|$\n",
    "\n",
    "Если правильно подобрать $K$, тогда соеденение признаком посредством хеширования не испортит модель, новый признак будет информативен так же, как они в раздельности. После хеширования могут возникнуть коллизии, но они не будут оказывать негативное воздействие.\n",
    "\n",
    "**Random projections** \n",
    "\n",
    "Имеется набор признаков $x$. Гененрируем набор весов из нормлаьного распределения $w \\sim \\mathcal{N}(0, 1)$, после добавляем новый признак $\\langle w, x \\rangle$. И так можно повторить много раз, если у нас есть миллион признаков, мы генерируем много векторов весов такой же размерности и заменяем старые признаки на скалярное произведение вектора весов на старые признаки.\n",
    "\n",
    "Данный метод позвоялет понижаеть размерность без большого влияния на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41b3ae",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">3.3 Кодирование с учётом целевой переменной</h2>\n",
    "\n",
    "### Для бинарной классификации\n",
    "\n",
    "$\\large \\mathbb{Y} = \\{1, 0\\}$\n",
    "\n",
    "$\\large g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$ (3.1)\n",
    "\n",
    "где $f_j(x_i)$ - $j$-й признак $i$-го объекта, $y_i$ - класс $i$-го объекта. \n",
    "\n",
    "$f_j(x)$ - Категория кодируемого объекта для $j$-го признака.\n",
    "\n",
    "$g_j(x, X)$ - Для $j$- го признака выполняем преобразование. На вход подается вся обучающая выборка $X$. Где $x$ - это некоторый объект признака к которому применяется кодирование. Мы на вход подаем каждый объект признака и кодируем его. Если категория у объекта повторяется и для него мы уже рассчитывали значение, тогда просто используем его.\n",
    "\n",
    "Суммируем по всем объектам обучающей выборки, выбирая те объекты $x_i$ на которых значение категориального признака $f_j(x_i)$ совпадает с значением категориального признака на объекте $f_j(x)$ для которого кодируем категорию и который при этом относится к положитлеьному классу. После делим на число объектов с таким значением категории."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04914595",
   "metadata": {},
   "source": [
    "**Другими словами:**\n",
    "\n",
    "Имеется $j$-й категориальный признак и мы хотим его заменить на числовой. Для этого, у конкретного объекта $x$ берем значение категориального признака $f_{j}(x)$. В числителе мы считаем количество объектов положительного класса, которые относятся к категории объекта $f_{j}(x)$. В знаменателе общее количество объектов признака, которые относятся к категории объекта $f_{j}(x)$. \n",
    "\n",
    "\n",
    "<img src=\"img/4_2.png\">\n",
    "\n",
    "Следовательно, мы выбрали все объекты с конкретным значение категориального признака $f_{j}(x)$ и внутри этих объектов, считаем долю положительного класса. Значит, мы получим долю объектов положитлеьного класса среди всех объектов некоторой категории. Для отрицательного класса, мы можем найти долю как $1 - g_j$. \n",
    "\n",
    "Мы получаем для каждой категории вероятность, того что объект с этой категорией относится к положительному классу.\n",
    "\n",
    "Если у некоторого признака все объекты у категории положитлеьные, это указывает на то, что скорее всего новый объект данной категории будет положительным. А если у некоторой категории половина объектов положительна, другая отрицательная, тогда значение признака будет равно $\\frac{1}{2}$ и для модели это не дает новой информации, так как новый объект с этой категорией равновероятно принимает значения положительного или отрицательного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eede2c34",
   "metadata": {},
   "source": [
    "### Для многоклассовой классификации\n",
    "\n",
    "$\\large \\mathbb{Y} = \\{1, \\ldots, K\\}$\n",
    "\n",
    "Отметим, что эту формулу легко перенести как на случай многоклассовой классификации (в этом случае будем считать $K$ признаков, по одному для каждого класса, и в числителе будет подсчитывать долю объектов с заданной категорией и с заданным классом), так и на случай регрессии (будем вычислять среднее значение целевой переменной среди объектов данной категории).\n",
    "\n",
    "$\\large g_{jk}(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = k]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$ (3.1.1)\n",
    "\n",
    "В числителе суммируем по всем объектам, ищем объекты с такой же категорией как у объекта $x$ и средни них считаем объекты только $k$-го класса. И делим на количество объектов данной категории. Тем самым, мы каждую категорию кодируем распределением на $K$ исходов, которое говорит о том, какая вероятность при некой категории получить свой класс.\n",
    "\n",
    "### Для регрессии\n",
    "\n",
    "$\\large \\mathbb{Y} = \\mathbb{R}$\n",
    "\n",
    "Мы считаем среднее значение целевой переменной внутри данной категории.\n",
    "\n",
    "$\\large g_{j}(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]y_i}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}$ (3.1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f426e9",
   "metadata": {},
   "source": [
    "### Переобучение\n",
    "\n",
    "Напряму считать новый признак под данным формулам будет плохой идеей, так как модель может переообучиться. Если у некоторой категории признака целевая переменная будет все время принимать один класс (у данной категории оказалось, например, всего два объекта и на них целева переменная совпала), тогда значение объектов с этой категорией у закодированного признака $g_j$ будет равно значению целевой переменной. \n",
    "\n",
    "Тем самым, модель увидит, что в столбец $g_j$ стоит ответ. Значит модель запоним закономерность, что ответ равняется $g_j(x)$ и не будет учитывать другие признаки. Так как значение целевой переменной было оценено малым количеством объектов, тогда данная оценка будет ненадежной, смешненной и так как модель доверяет данной оценке, она может переобучиться. \n",
    "\n",
    "**Пример.** Если имеется много категорий, где в каждой категории очень мало объектов и такие категории в сумме составляют 80% выборки. Остальные категории составляют 20% выборки, внутри которых нормальное количество объектов. Следовательно, модель переобучится под категории с небольшим количеством объектов, так как эти категории в сумме составляют 80% выборки, поэтому они оказывают на модель основное влияние, но в этих категориях мало объктов, значит там может оказаться значение целевой переменой, что и приводит к переобучению.\n",
    "\n",
    "### Борьба с переобучением\n",
    "\n",
    "И нам необходимо, чтобы модель могла опираться на значение счетчика только в случае высокой уверенности того, что оценка внутри данной категории скорее всего соответствует классу целевой переменной.\n",
    "\n",
    "$\\large g_j(x, X)\n",
    "=\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "        +\n",
    "        \\frac{C}{\\ell}\n",
    "        \\sum_{i=1}^{\\ell}\n",
    "        [y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "    [f_j(x) = f_j(x_i)] + C\n",
    "}$ (3.2)\n",
    "\n",
    "где $C$ – коэффициент, отвечающий за баланс между средним значением по категории и глобальным средним значением (гиперпараметр).\n",
    "\n",
    "**Идея формулы:**\n",
    "\n",
    "Предположим, что $C = 100$ и всего один объект в кодируемой категории. Тогда, в сумме числителя $\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]$ будет еденица, если единственный объект положителен, ноль если единственный объект отрицателен. А в знаменателе сумма $\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]$ тоже равна $1$.\n",
    "\n",
    "Если значение целевой переменной равно $1$, тогда классическая формула $g_j$ (без правой) вернет $1$, так как в числителе и знаменателе будут $1$. Получается что правая часть будет оказывать воздействи на результат:\n",
    "\n",
    "$\\large \\frac{C}{\\ell} \\sum_{i=1}^{\\ell} [y_i = +1]$ - доля положительный объектов в выборке умноженное на $C$. \n",
    "\n",
    "Так как в знаменателе мы делим на $C$, тогда $C$ просто сокращаются и данная дробь будет близка к доле положительных объектов в выборке. Чем больше в категории будет объектов с положительной целевой переменной (две суммы слева), тем больше влияение на результут дроби они будут оказывать, так как поправка $C$ будет вносить меньший вклад.\n",
    "\n",
    "**Вывод:**\n",
    "\n",
    "Если мало объектов в данной категории, тогда $g_j(x, X) \\approx \\frac{1}{\\ell} \\sum_{i=1}^{\\ell} [y_i = +1]$ будет примерно равно доли положительных объектов в выборке. Тогда модель не сможет переобучиться под такое значение, так как доля положительных объектов в выборке не содержит информации о объекте и модель не сможет узнать ответ на конкретном объекте.\n",
    "\n",
    "А если объектов много, тогда $g_j(x, X) \\approx \\text{классической формуле}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678098b",
   "metadata": {},
   "source": [
    "### Почему выходы других моделей приводят к переобучению?\n",
    "\n",
    "$g_j(x, X)$ является простой моделью, так как это число посчитанное с учетом целевой переменной. И тогда $a(x)$, которая обучается на новых признаках будет иметь выходы другой простой модели. \n",
    "\n",
    "Почему если среди признаков есть выходы другой модели? Если мы уверены что признаки имееют одинаковый смысл как обучающей так и на тестовой выборке, например, цвет автомобиля там и там будет иметь один смысл. Но этот признак на основе выхода модели может изменить свой смысл и если модель $g_j(x, X)$ будет переобучена, тогда качество на обучающей выборке будет выше чем на тестовой. Это происходит из-за того, что мы использовали целевую переменную обучащей выборки. Ну и логично, что новые категории с учетом целевой переменной будут давать больше информации на обучающей выборке, чем на тестовой.\n",
    "\n",
    "Когда модель будет обучаться на обучающей выборке, модель $a(x)$ заметит что признак оказывает большое влияние на предсказание и модель будет на него пологаться. Но когда модель $a(x)$ будет применена на тестовой выборке, модель будет уверена что это признак является хорошим, но так как выход простой модели изменил смысл признака, это не так. Почему смысл признака был изменен? Так как мы обучали признак (кодировали) на обучающей выборке с известными целевыми переменными, а на тренировочной выборке нам целевые переменные неизвестны, тогда мы заменяем (кодируем) категории признаков используя уже обученную модель, котора могла подогнаться под обучающую выборку. Именно поэтому мы подбираем $C$ по тренировочной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60122b0c",
   "metadata": {},
   "source": [
    "### Кросс-валидация\n",
    "\n",
    "Разделяем обучающую выборку на $K$ блоков. Возьмем $K=3$, если необходимо посчитать счетчики для третьего блока, тогда мы берем первый и второй блок, по ним считаем статистику:\n",
    "\n",
    "$\\large \\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]$ - количество объектов данной категории для положительного класса\n",
    "\n",
    "$\\large \\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]$ - общее количество объектов данной категории\n",
    "\n",
    "И счетчики на третьем блоке мы вычисляем на основе статистик посчитаных на первом и втором блоке, то есть подставляем эти статистики в формулу $g_j$. Получаем, что счетчик посчитанный на третьем блоке не использует информацию о целевой переменной, а значит модели будет сложнее переобучиться. Аналогично можем посчитать остальные блоки.\n",
    "\n",
    "**А что если у нас много категорий и по многим категориям мало объектов?**\n",
    "\n",
    "Если имеются категории, где мало объектов с одним значением целевой переменной, например два объекта, тогда один объект может попасть в первый блок, а другой в третий. Что получается? Счетчик для первых двух блоков будет равен значению целевой переменной на этой категории и в третий блок мы запишем его, то есть запишем знацение целевой переменной, дадим модели ответ. Для решения этой проблемы необходимо использовать улучшения счетчика которые мы придумали или же (Trash bucket/Хеширование).\n",
    "\n",
    "Есил Trash bucket/Хеширование решает эту проблему на первом варианте, для чего нужна кросс-валидация? Мы обсуждали проблему того, что счетчик это простая модель, которая может переобучиться под обучающую выборку и кросс-валидация помогает решить данную проблему. Тем самым, модель, которая будет обучаться поверх счетчиков рассчитанных на кроссвалидации, будет иметь информацию того, как счетчики работают на новых данных и не будет проблемы смещения целевой переменной.\n",
    "\n",
    "**Как считать счетчики для тестовой выборки?**\n",
    "\n",
    "Для тестовой выборки мы считаем статистики по всей обучающей выборке и рассчитывает счетчики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4483e",
   "metadata": {},
   "source": [
    "### Кросс валидация и кросс валидация счетчиков\n",
    "\n",
    "Если мы рзбили выборку на $K$ блоков для кросс валидации модели, возьмем $K = 3$, где первы два блока выступают для обучения модели (1-я часть рисунка).\n",
    "\n",
    "<img src=\"img/4_1.png\">\n",
    "\n",
    "Чтобы обучить модель на первых двух блоках, мы должны посчитать там значени счетчиков. Для этого разбиваем первый блок на $3$ части и считаем статистики для счетчиков. Теперь аналогично  разбиваем второй блок на $3$ части и считаем счетчики для этого блока. После мы можем обучить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86090cf1",
   "metadata": {},
   "source": [
    "### Зашумление\n",
    "\n",
    "Можно посчитать новые признаки по базовой формуле (3.1), а затем просто добавить к каждому значению случайный шум (например, нормальный). Это\n",
    "действительно снизит уровень корреляции счётчиков с целевой переменной. Проблема в том, что это делается за счёт снижения силы такого признака, а значит, мы ухудшаем итоговое качество модели. Поэтому важно подбирать дисперсию шума, чтобы соблюсти баланс между борьбой с переобучением и предсказательной силой счётчиков.\n",
    "\n",
    "$\\large \\tilde{g}_{j}(x, X) = g_{j}(x, X) +  \\mathcal{N}(\\mu, \\sigma^2)$,\n",
    "\n",
    "где  $\\mathcal{N}(\\mu, \\sigma^2)$ — нормальное распределение\n",
    "со средним $\\mu = 0$ и дисперсией $\\sigma^2$. \n",
    "\n",
    "\n",
    "Здесь необходимо правильно подобрать $\\sigma^2$, так чтобы на маленьких категориях сильно зашумлялся признак, а на больших категориях нужно не сильное зашумление, так как эти категории несут в себе полезную информацию и на них сложно переобучиться (в больших категориях нет ответа целевой переменной). А это возможно если $\\sigma^2 (f_j(x))$ зависит от категорий на данном объекте, то есть, для каждой категории свой шум, что весьма сложная задача."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53bc68",
   "metadata": {},
   "source": [
    "### Сглаживание\n",
    "\n",
    "Можно немного модифицировать формулу (3.2) ,чтобы сила регуляризации зависела от объёма данных по конкретной категории. Другими словами, если в категории много примеров, тогда регуляризация будет иметь низкий эффект, так как утечка минимальна, а если в категории мало примеров, тогда будет высокий риск утечки и для этого надо применить регуляризацию.\n",
    "\n",
    "\n",
    "$ g_j(x, X)\n",
    "=\n",
    "\\lambda \\left( n(f_j(x)) \\right)\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{\\ell}\n",
    "    [f_j(x) = f_j(x_i)]\n",
    "}\n",
    "+\n",
    "\\left( 1 - \\lambda \\left( n(f_j(x)) \\right) \\right)\n",
    "\\frac{1}{\\ell}\n",
    "\\sum_{i = 1}^{\\ell}\n",
    "    [y_i = +1]$\n",
    "\n",
    "где $n(z) = \\sum_{i = 1}^{\\ell} [f_j(x_i) = z]$ - число объектов категории $z$, в формуле это имеет вид, что тоже самое $n(f_j(x))$ - число объектов данной категорией в выборке.\n",
    "\n",
    "$\\lambda(n)$ - некоторая монотонно возрастающая функция, дающая значения из отрезка $[0, 1]$.\n",
    "\n",
    "Примером может служить $\\lambda(n) = \\frac{1}{1 + \\exp(-n)}$.\n",
    "Если грамотно подобрать эту функцию, то она будет вычищать значение целевой переменной из редких категорий и мешать переобучению. \n",
    "\n",
    "Если категория будет большой по размеру функция будет отдавать предпочтени первому слогаемому, если маленькая тогда второму. Идея заключается в том, что чем меньше значений в категории, тем значение счетчика будет больше сдвигать к среднему значению класса по всей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb28ea",
   "metadata": {},
   "source": [
    "### Кодирование по времени\n",
    "\n",
    "Зададим порядок для обучающей выборки. И когда мы будем считать счетчики на некотором объекте, то мы бдуем использовать информацию об объектах, которые расположены до текщуего.\n",
    "\n",
    "$\\large g_j(x_k, X)\n",
    "=\n",
    "\\frac{\n",
    "    \\sum_{i=1}^{k - 1}\n",
    "        [f_j(x) = f_j(x_i)][y_i = +1]\n",
    "}{\n",
    "    \\sum_{i=1}^{k - 1}\n",
    "        [f_j(x) = f_j(x_i)]}$\n",
    "\n",
    "Получается, что счетчики на каждом объекте учитывают информацию о целевой переменной только на части объектов. Причем, чем позже стоит объект в выборке, тем большую часть выборки захватывает статистика по которой считаются счетчики для объекта. \n",
    "\n",
    "Это хорошо позволяет бороться с переобучением, так как счетчики будут рассчитаны хорошо на последних объектах, поэтому на большей части объектов этот признак будет оказывать не очень сильное влияние и это будет мешать модели переобучиться на нем.\n",
    "\n",
    "Данный метод хорошо работает если мы несколько раз отсортируем выборку (100 раз) и по каждому порядку посчитаем такие счетчики (получим 100 признаков).\n",
    "\n",
    "**Почему данному методу сложнее переобучиться?**\n",
    "\n",
    "Если же в методах выше, счетчик для определенной категории принимал строго одно значение, то при с кодирование по времени у одной категории счетчик может равнятся разным значеним, так как мы перемещаемся по выборке. Из-за этого модель не сможет понять закономерность того, что счетчик это и есть ответ целевой переменной.\n",
    "\n",
    "Даже в примере, когда в категории два объекта, счетчик мог передать ответ, так как мы считали значение счетчика по одному объекту. В этом случае на первом объекте значение счетчика будет равно нулю, так как выше нет объектов данной категории, а на втором объекте мы получим значение первого объекта, например один. Следовательно, мы закодировали одну категорию двумя значениями, из-за чего модель не определит значение целевой переменной на этой категории и модель будет учитывать другие признаки тоже, что нам и необходимо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3489e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">4. Извлечение признаков из текстов</h1>\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.1 Bag-of-words</h2>\n",
    "\n",
    "Простой способ заключается в подсчёте, сколько раз встретилось каждое слово\n",
    "в тексте. Получаем вектор длиной в количество уникальных слов, встречающихся во всех объектах выборки. В таком векторе много нулей, поэтому его удобнее хранить в разреженном виде (где каждому признаку соответствует то, сколько раз $N$-ое слово встречается в тексте). Такой способ представления текстов называют мешком слов (так как мы убрали порядок и не можем восстановить порядок слов).\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.2 TF-IDF</h2>\n",
    "\n",
    "Считаем два показателя для текста:\n",
    "\n",
    "**TF (Term Frequency)** - количество вхождений слова в отношении к общему числу слов в тексте, другими словаи это доля некого слова в документе:\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$\n",
    "\n",
    "где $n_{td}$ \" - количество вхождений слова $t$ в текст $d$\n",
    "\n",
    "$\\sum_{t \\in d} n_{td}$ - общее количество слов в документе.\n",
    "\n",
    "**IDF (Inverse Document Frequency)**:\n",
    "\n",
    "Некторые слова встречаются в каждом документе и если у нас в тексте встретилось слово \"но\", то оно скорее всего ничего не значит, а слово которое встречается редко скорее всего имеет большое значение. И для этого мы можем добавить в признак информацию о том, насколько слово характерно для определенного документа.\n",
    "\n",
    "$$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$\n",
    "\n",
    "где $D$ - набор всех документов.\n",
    "\n",
    "В числителе у нас число документов, а в знаменателе $\\left| \\{d\\in D: t \\in d\\} \\right|$ \" - количество текстов в коллекции, содержащих слово $t$, другими словами это число документов, в которых встречается данное слово. \n",
    "\n",
    "**tf-idf**\n",
    "\n",
    "Тем самым чем более уникально слово, тем выше будет $\\text{idf}$. Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "\n",
    "$$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "**Почему берем логарифм у idf?** Берем логариифм, так как нам важен только порядок (слово в стречается в 1, 10 или 100 документов). \n",
    "\n",
    "При этом для нас $\\text{tf}$ имеет большое значение и из-за логарифма у $\\text{idf}$ во время рассчета $\\text{tf-idf}$ мы будем изменять $\\text{tf}$ только в зависимости от порядка документов в котором встречается слово.\n",
    "\n",
    "<h2 style=\"color:#008B8B\">4.3 N-граммы</h2>\n",
    "\n",
    "В этом случае словарь состоить не только из отдельных слов, но из словосочетаний."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
