{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black\" align=\"center\">Линейная классификация</h1>\n",
    "\n",
    "<h1 style=\"color:#008B8B\">1. Линейные модели классификации</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\mathbb{X} = \\mathbb{R}^n$ пространство объектов.\n",
    "\n",
    "$\\mathbb{Y} = \\{-1, +1\\}$ - множество допустимых ответов. \n",
    " * Если $y = 1$ - положительный объект\n",
    " * $y = -1$ - отрицательный объект.\n",
    "\n",
    "$X = \\{(x_i, y_i)\\}_{i = 1}^{\\ell}$ - обучающая выборка.\n",
    "\n",
    "Линейная модель имеет следующий вид: \n",
    "\n",
    "$\\large a(x) = sign (\\langle w, x \\rangle + w_0)$\n",
    "\n",
    "Уравнение $\\langle w, x \\rangle + w_0 = 0$ определяет гиперплоскость у которой $w$ - это вектор нормали.\n",
    "\n",
    " * Если $\\langle w, x \\rangle + w_0 = 0$ тогда точка лежит на гиперплоскости;\n",
    " * Если $\\langle w, x \\rangle + w_0 > 0$ тогда точка лежит на одной из полуплоскостей;\n",
    " * Если $\\langle w, x \\rangle + w_0 > 0$ тогда точка лежит на второй полуплоскости.\n",
    "\n",
    "<img src=\"img/4_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">1.1 Обучение линейных классификаторов</h2>\n",
    "\n",
    "Функционал ошибки будет выглядеть следующим образом:\n",
    "\n",
    "$\\large Q(a, X) = \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [a(x_i) = y_i]$ - долей правильных ответов (accuracy)\n",
    "\n",
    "Нам будет удобнее решать задачу минимизации, поэтому будем вместо этого использовать долю неправильных ответов:\n",
    "\n",
    "$\\large Q(a, X) = \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [a(x_i) \\ne y_i]$ - доля ошибок.\n",
    "\n",
    "Если не сказано иначе, мы будем считать, что среди признаков есть константа, $x_{d + 1} = 1$. В этом случае нет необходимости вводить сдвиг $w_0$, и линейный классификатор можно задавать как\n",
    "\n",
    "$\\large a(x) = sign (\\langle w, x \\rangle)$\n",
    "\n",
    "Подставим в функцию потерь модель:\n",
    "\n",
    "$\\large \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [sign (\\langle w, x \\rangle) \\ne y_i] \\to \\underset{w}{\\text{min}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как оптимизировать функционал?**\n",
    "\n",
    "Как мы решаем задачи оптимизации? Можем найти точное решение посчитав градиент или использовать градиентный спуск, где в двух случаях необходимо посчитать частные производные функционала по вектору весов. Но, веса расположены под знаком $sign$, который не является дифференцируемой функцией и всё это расположено внутри идникатора, который тоже не является дифференцируемой функцией.\n",
    "\n",
    "**Выполним преобразование функционала ошибки**\n",
    "\n",
    "$\\large \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [y_i \\langle w, x \\rangle < 0] \\to \\underset{w}{\\text{min}}$\n",
    "\n",
    "Утвержается, что стоит под индекатором $sign (\\langle w, x \\rangle) \\ne y_i$ эквивалентно $y_i \\langle w, x \\rangle < 0$.\n",
    "\n",
    "$\\large y_i \\langle w, x \\rangle > 0$ означает, что $y_i$ и $\\langle w, x \\rangle$ одного знака, а если они одного знака, тогда мы правильно угадали класс. Значит, ответ верный.\n",
    "\n",
    "$\\large y_i \\langle w, x \\rangle < 0$ в данном случае, значение слева меньше нуля, значит $y_i$ и $\\langle w, x \\rangle$ разного знака и ответ неверный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отступы\n",
    "\n",
    "Заметим, что функционал (1.1) можно несколько видоизменить:\n",
    "\n",
    "$\\large Q(a, X) = \\frac{1}{\\ell} \\sum_{i = 1}^{\\ell} [\\underbrace{y_i \\langle w, x_i \\rangle}_{M_i} < 0] \\to \\underset{w}{\\text{min}}$\n",
    "\n",
    "$\\large M_i = y_i \\langle w, x \\rangle$ - отступ (margin)\n",
    "\n",
    "Знак отступа говорит о корректности ответа классификатора (положительный отступ соответствует правильному ответу, отрицательный — неправильному), а абсолютная величина отступа (напримр, большой отступ или маленький по модулю) характеризует степень уверенности классификатора в своём ответе.\n",
    "\n",
    "Абсолютное значение отступа $\\large |M_i|$ это расстояние от $x_i$ до разделяющей гиперплоскости. Если $L_2$ норма вектора весов равна $1$, тогда отступ является расстоянием до разделяющей гиперплоскости. Если $L_2$ норма вектора весов не равна $1$, тогда это отмасштабированное расстояние. Но по идеии, чем больше значение отступа, тем больше расстояние до разделяющей гиперплоскости, значит и уверенность классификатора в своём ответе будет выше.\n",
    "\n",
    "Если модель уверенна в своём ответе на некотором объекте и она ошиблась, тогда объект скорее всего является выбросом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Верхние оценки\n",
    "\n",
    "$\\large \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [y_i \\langle w, x \\rangle < 0]$\n",
    "\n",
    "В данном функционале используется следующая функция потерь:\n",
    "\n",
    "$\\large L(M) = [M < 0]$\n",
    "\n",
    "Посмторим как данная функция потерь выглядит на графике (синий цвет):\n",
    "\n",
    "<img src=\"img/4_2.png\">\n",
    "\n",
    "Мы можем ввести верхнюю оценку для пороговой функции потерь, чтобы производить обучение модели.\n",
    "\n",
    "$\\large L(M) = [M < 0] \\le \\tilde L(M)$\n",
    "\n",
    "После этого можно получить верхнюю оценку на функционал:\n",
    "\n",
    "$\\large 0 \\le \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [y_i \\langle w, x \\rangle < 0] \n",
    "\\le \n",
    " \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} \\tilde L (y_i \\langle w, x \\rangle) \\to \\underset{w}{\\text{min}}$\n",
    "\n",
    "И после этого, отсаётся минимизировать верхнюю оценку. Так как изначальный функционал ошибки не меньше нуля и при этом мы минимизруем верхнюю оценку, тогда и доля неправильных ответов тоже станет небольшой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если верхняя оценка~$\\tilde L(M)$ является гладкой, то и данная верхняя оценка будет гладкой.\n",
    "В этом случае её можно будет минимизировать с помощью, например, градиентного спуска.\n",
    "Если верхнюю оценку удастся приблизить к нулю, то и доля неправильных ответов тоже будет близка к нулю.\n",
    "\n",
    "Приведём несколько примеров верхних оценок:\n",
    "\n",
    "$\\large \\tilde L(M) = \\log \\left(1 + e^{-M} \\right)$ - логистическая функция потерь\n",
    "\n",
    "$\\large \\tilde L(M) = (1 - M)_+ = \\max(0, 1 - M)$-  кусочно-линейная функция потерь (используется в методе опорных векторов)\n",
    "\n",
    "$\\large \\tilde L(M) = (-M)_+ = \\max(0, -M)$ - кусочно-линейная функция потерь~(соответствует персептрону Розенблатта)\n",
    "\n",
    "$\\large \\tilde L(M) = e^{-M}$ - экспоненциальная функция потерь\n",
    "\n",
    "$\\large \\tilde L(M) = 2/(1 + e^M)$ - сигмоидная функция потерь\n",
    "\n",
    "Любая из них подойдёт для обучения линейного классификатора.\n",
    "Позже мы подробно изучим некоторые из них и выясним, какими свойствами они обладают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#008B8B\">2. Метрики качества классификации</h1>\n",
    "\n",
    "<h2 style=\"color:#008B8B\">2.1 Доля правильных ответов</h2>\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "$\\large accuracy(a, X) = \\frac{1}{\\ell} \\sum\\limits_{i=1}^{\\ell} [a(x_i) = y_i]$ - долей правильных ответов.\n",
    "\n",
    "Если выборка несбалансированная, допустим, имеется $950$ здоровых людей (из относим к классу -1) и $50$ людей которые болеют некоторой белезнью (относим к классу 1).\n",
    "\n",
    "Мы можем посторить такую модель, которая всегда будет возвращать отрицательный класс (говорит о том, что человек здоров). У этой модели доля верных ответов составит $0.95$. И данная модель нас не устраивает так как цена ошибки различается.\n",
    "\n",
    "### Относительная ошибка\n",
    "\n",
    "Если доля ошибок была улучшена с 20% до 10%, то относительное улучшение составляет 50%. Если доля ошибок была улучшена с 50% до 25%, то относительное\n",
    "улучшение также равно 50%, хотя данный прирост кажется более существенным.\n",
    "Если же доля ошибок была улучшена с 0.1% до 0.01%, то относительное улучшение\n",
    "составляет 90%, что совершенно не соответствует здравому смыслу.\n",
    "\n",
    "|$$r_1$$   |$$r_2$$      |$$r_1 - r_2$$ |$$\\frac{r_1 - r_2}{r_1}$$ |\n",
    "|:--------:|:-----------:|:------------:|:------------------------:|\n",
    "|20%       |10%          |10%           |50%                       |        \n",
    "|50%       |25%          |25%           |50%                       |\n",
    "|0.1%      |0.01%        |0.09%         |90%                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#008B8B\">2.2 Матрица ошибок</h2>\n",
    "\n",
    "|            |$$y=1$$             |$$y=-1$$             |\n",
    "|:----------:|:------------------:|:-------------------:|\n",
    "|$a(x) = 1$  |True Positive (TP)  |False Positive (FP)  |        \n",
    "|$a(x) = -1$ |False negative (FN) |True Negative (TN)   |\n",
    "\n",
    "\n",
    "Гораздо более информативными критериями являются точность (precision)\n",
    "и полнота (recall):\n",
    "\n",
    "$\\large \\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ - Метрика точности, показывает насколько можно доверять модели в случае срабатывании. \n",
    "\n",
    "В знаменателе $\\text{TP} + \\text{FP}$ - это все клиенты, которым был выдан кредит. В числителе $\\text{TP}$ - те клиенты, которые вернули кредит. \n",
    "\n",
    "Модель может выдать кредит только одному пользователю и $\\text{precision}$ будет 100%, но модель может не выдавать кредит людям, которые его бы вернули.\n",
    "\n",
    "$\\large \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ - Метрика полноты, показывает насколько задействованы клиенты, которые вернули бы кредит.\n",
    "\n",
    "В знаменателе $\\text{TP} + \\text{FN}$ - стоят все те, кто обязательно вернут кредит. В числителе $\\text{TP}$ - те клиенты, которые вернули кредит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение точности и полноты\n",
    "\n",
    "|                    |$\\text{Model 1}$   |$\\text{Model 2}$   |\n",
    "|:------------------:|:-----------------:|:-----------------:|\n",
    "|$\\text{precision}$  |$0.1$              |$0.55$             |        \n",
    "|$\\text{recall}$     |$1$                |$0.55$             |\n",
    "\n",
    "### Арифметическое среднее\n",
    "\n",
    "$\\large A = \\frac{1}{2} (precision + recall)$\n",
    "\n",
    "$\\large \\text{A(Model 1)} = 0.55$\n",
    "\n",
    "$\\large \\text{A(Model 2)} = 0.55$\n",
    "\n",
    "Несмторя на то, что вторая модель лучше первой, среднее арифметическое имеет одно значение. Можем заметить, что эти два алгоритма расположены на одной линии уровня.\n",
    "\n",
    "<img src=\"img/4_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимум\n",
    "\n",
    "$\\large \\text{MIN} = min(precision, recall)$ \n",
    "\n",
    "Подход с взятием минимума решает проблему для модели выше. Но у этой модели имеетсся другая проблема. Предположим у нас есть две модели:\n",
    "\n",
    "|                    |$\\text{Model 1}$     |$\\text{Model 2}$   |\n",
    "|:------------------:|:-------------------:|:-----------------:|\n",
    "|$\\text{precision}$  |$0.4$                |$0.4$              |        \n",
    "|$\\text{recall}$     |$0.5$                |$0.9$              |\n",
    "\n",
    "У двух моделей точность равна 0.4, но полнота первой модели 0.5, а второй модели 0.9. И несложно понять, что второй алгоритм лучше. Но минимум у двух моделей будет равен $0.4$.\n",
    "\n",
    "Если начинает возрастать второй парамтр, тогда оцнка не сможет использовать эту информацию. Это хорошо видно на линиях уровня, если зафиксировать один параметр и увеличивать другой, то линия уровня будет прямой.\n",
    "\n",
    "<img src=\"img/4_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Метра\n",
    "Решением данной проблемы становится метрика гармонического среднего:\n",
    "\n",
    "$\\large F = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$\n",
    "\n",
    "$Model_1 = 0.44$\n",
    "\n",
    "$Model_2 = 0.55$\n",
    "\n",
    "Как видно, вторая модель лучше. Вторая точка будет расположена вверхнем углу на салатовой линии уровня. \n",
    "\n",
    "Имеется модификация F-меры, которая позволят выбрать что важнее, точность или полнота:\n",
    "\n",
    "$\\large F_{\\beta} = (1 + \\beta^2) \\frac{\\text{precision} \\cdot \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}$\n",
    "\n",
    "<img src=\"img/4_5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
